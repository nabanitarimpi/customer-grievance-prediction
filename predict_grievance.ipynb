{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (16,17,18,19,20,22,23,24,25,26,27,28,45,49,50,51) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (14,15,16,17,18,19,20,22,23,24,25,49,50,51) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed data type columns in the training set :  Index(['issue.15', 'issue.16', 'issue.17', 'issue.18', 'issue.19', 'issue.20',\n",
      "       'issue.21', 'issue.22', 'issue.23', 'issue.24', 'issue.25', 'issue.26',\n",
      "       'parties.2', 'respondent.2', 'respondent.3', 'respondent.4'],\n",
      "      dtype='object')\n",
      "Mixed data type columns in the test set :  Index(['issue.13', 'issue.14', 'issue.15', 'issue.16', 'issue.17', 'issue.18',\n",
      "       'issue.19', 'issue.20', 'issue.21', 'issue.22', 'issue.23',\n",
      "       'respondent.2', 'respondent.3', 'respondent.4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# columns with mixed types in both train and test sets\n",
    "train_mixed_id = [16,17,18,19,20,22,23,24,25,26,27,28,45,49,50,51]\n",
    "test_mixed_id = [14,15,16,17,18,19,20,22,23,24,25,49,50,51]\n",
    "\n",
    "mixed_cols_train = train_df.iloc[:,train_mixed_id].columns\n",
    "mixed_cols_test = test_df.iloc[:,test_mixed_id].columns\n",
    "\n",
    "print(\"Mixed data type columns in the training set : \", mixed_cols_train)\n",
    "print(\"Mixed data type columns in the test set : \", mixed_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appno</th>\n",
       "      <th>application</th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>country.name</th>\n",
       "      <th>decisiondate</th>\n",
       "      <th>docname</th>\n",
       "      <th>doctypebranch</th>\n",
       "      <th>ecli</th>\n",
       "      <th>introductiondate</th>\n",
       "      <th>issue.0</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_article=6</th>\n",
       "      <th>ccl_article=7</th>\n",
       "      <th>ccl_article=8</th>\n",
       "      <th>ccl_article=9</th>\n",
       "      <th>ccl_article=p1</th>\n",
       "      <th>ccl_article=p12</th>\n",
       "      <th>ccl_article=p4</th>\n",
       "      <th>ccl_article=p6</th>\n",
       "      <th>ccl_article=p7</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2052/08</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ru</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF KOKOSHKINA v. RUSSIA</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2009:0528JUD000205208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4728/07</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>tr</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF ÖZCAN v. TURKEY</td>\n",
       "      <td>COMMITTEE</td>\n",
       "      <td>ECLI:CE:ECHR:2018:0710JUD000472807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44135/06</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>si</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF DANIJEL PEČNIK v. SLOVENIA</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2012:1018JUD004413506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2607/08</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ch</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF PALANCI v. SWITZERLAND</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2014:0325JUD000260708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27001/06</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ru</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF AMANAT ILYASOVA AND OTHERS v. RUSSIA</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2009:1001JUD002700106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      appno application country.alpha2        country.name decisiondate  \\\n",
       "0   2052/08     MS WORD             ru  Russian Federation          NaN   \n",
       "1   4728/07     MS WORD             tr              Turkey          NaN   \n",
       "2  44135/06     MS WORD             si            Slovenia          NaN   \n",
       "3   2607/08     MS WORD             ch         Switzerland          NaN   \n",
       "4  27001/06     MS WORD             ru  Russian Federation          NaN   \n",
       "\n",
       "                                        docname doctypebranch  \\\n",
       "0                  CASE OF KOKOSHKINA v. RUSSIA       CHAMBER   \n",
       "1                       CASE OF ÖZCAN v. TURKEY     COMMITTEE   \n",
       "2            CASE OF DANIJEL PEČNIK v. SLOVENIA       CHAMBER   \n",
       "3                CASE OF PALANCI v. SWITZERLAND       CHAMBER   \n",
       "4  CASE OF AMANAT ILYASOVA AND OTHERS v. RUSSIA       CHAMBER   \n",
       "\n",
       "                                 ecli introductiondate issue.0  ...  \\\n",
       "0  ECLI:CE:ECHR:2009:0528JUD000205208              NaN     NaN  ...   \n",
       "1  ECLI:CE:ECHR:2018:0710JUD000472807              NaN     NaN  ...   \n",
       "2  ECLI:CE:ECHR:2012:1018JUD004413506              NaN     NaN  ...   \n",
       "3  ECLI:CE:ECHR:2014:0325JUD000260708              NaN     NaN  ...   \n",
       "4  ECLI:CE:ECHR:2009:1001JUD002700106              NaN     NaN  ...   \n",
       "\n",
       "  ccl_article=6 ccl_article=7 ccl_article=8 ccl_article=9 ccl_article=p1  \\\n",
       "0             0             0             0             0              0   \n",
       "1             0             0             0             0              0   \n",
       "2             1             0             0             0              0   \n",
       "3             0             0            -1             0              0   \n",
       "4             0             0             0             0              0   \n",
       "\n",
       "  ccl_article=p12 ccl_article=p4 ccl_article=p6 ccl_article=p7 importance  \n",
       "0               0              0              0              0          4  \n",
       "1               0              0              0              0          4  \n",
       "2               0              0              0              0          4  \n",
       "3               0              0              0              0          4  \n",
       "4               0              0              0              0          4  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appno</th>\n",
       "      <th>application</th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>country.name</th>\n",
       "      <th>decisiondate</th>\n",
       "      <th>docname</th>\n",
       "      <th>doctypebranch</th>\n",
       "      <th>ecli</th>\n",
       "      <th>introductiondate</th>\n",
       "      <th>issue.0</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_article=5</th>\n",
       "      <th>ccl_article=6</th>\n",
       "      <th>ccl_article=7</th>\n",
       "      <th>ccl_article=8</th>\n",
       "      <th>ccl_article=9</th>\n",
       "      <th>ccl_article=p1</th>\n",
       "      <th>ccl_article=p12</th>\n",
       "      <th>ccl_article=p4</th>\n",
       "      <th>ccl_article=p6</th>\n",
       "      <th>ccl_article=p7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1194/04</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>mk</td>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF CAMINSKI v. \"THE FORMER YUGOSLAV REPUB...</td>\n",
       "      <td>COMMITTEE</td>\n",
       "      <td>ECLI:CE:ECHR:2011:0224JUD000119404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53865/11</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ua</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF KUSHCH v. UKRAINE</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2015:1203JUD005386511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43838/07</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ie</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF O. v. IRELAND</td>\n",
       "      <td>COMMITTEE</td>\n",
       "      <td>ECLI:CE:ECHR:2012:0119JUD004383807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11157/04</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ru</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF ANCHUGOV AND GLADKOV v. RUSSIA</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2013:0704JUD001115704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Articles 32-33,134 and 135 of the Constitution</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42443/02</td>\n",
       "      <td>MS WORD</td>\n",
       "      <td>ru</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASE OF EMINBEYLI v. RUSSIA</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>ECLI:CE:ECHR:2009:0226JUD004244302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Articles 1, 11, 89, 96 and 122 of the Code of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      appno application country.alpha2        country.name decisiondate  \\\n",
       "0   1194/04     MS WORD             mk     North Macedonia          NaN   \n",
       "1  53865/11     MS WORD             ua             Ukraine          NaN   \n",
       "2  43838/07     MS WORD             ie             Ireland          NaN   \n",
       "3  11157/04     MS WORD             ru  Russian Federation          NaN   \n",
       "4  42443/02     MS WORD             ru  Russian Federation          NaN   \n",
       "\n",
       "                                             docname doctypebranch  \\\n",
       "0  CASE OF CAMINSKI v. \"THE FORMER YUGOSLAV REPUB...     COMMITTEE   \n",
       "1                          CASE OF KUSHCH v. UKRAINE       CHAMBER   \n",
       "2                              CASE OF O. v. IRELAND     COMMITTEE   \n",
       "3             CASE OF ANCHUGOV AND GLADKOV v. RUSSIA       CHAMBER   \n",
       "4                        CASE OF EMINBEYLI v. RUSSIA       CHAMBER   \n",
       "\n",
       "                                 ecli introductiondate  \\\n",
       "0  ECLI:CE:ECHR:2011:0224JUD000119404              NaN   \n",
       "1  ECLI:CE:ECHR:2015:1203JUD005386511              NaN   \n",
       "2  ECLI:CE:ECHR:2012:0119JUD004383807              NaN   \n",
       "3  ECLI:CE:ECHR:2013:0704JUD001115704              NaN   \n",
       "4  ECLI:CE:ECHR:2009:0226JUD004244302              NaN   \n",
       "\n",
       "                                             issue.0  ... ccl_article=5  \\\n",
       "0                                                NaN  ...             0   \n",
       "1                                                NaN  ...             1   \n",
       "2                                                NaN  ...             0   \n",
       "3     Articles 32-33,134 and 135 of the Constitution  ...             0   \n",
       "4  Articles 1, 11, 89, 96 and 122 of the Code of ...  ...             1   \n",
       "\n",
       "  ccl_article=6 ccl_article=7 ccl_article=8 ccl_article=9 ccl_article=p1  \\\n",
       "0             1             0             0             0              0   \n",
       "1             0             0             0             0              0   \n",
       "2             1             0             0             0              0   \n",
       "3             0             0             0             0              0   \n",
       "4             0             0             0             0              0   \n",
       "\n",
       "  ccl_article=p12 ccl_article=p4 ccl_article=p6 ccl_article=p7  \n",
       "0               0              0              0              0  \n",
       "1               0              0              0              0  \n",
       "2               0              0              0              0  \n",
       "3               0              0              0              0  \n",
       "4               0              0              0              0  \n",
       "\n",
       "[5 rows x 327 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset : (8878, 328)\n",
      "The shape of the test dataset : (4760, 327)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training dataset : {}\".format(train_df.shape))\n",
    "print(\"The shape of the test dataset : {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% of null values in the training set')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_null_cols = train_df.isnull().sum().sort_values(ascending=False)/len(train_df)*100\n",
    "train_null_cols[:40].plot(kind='bar', figsize=(14,10))\n",
    "plt.ylabel(\"% of null values in the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% of null values in the training set')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_null_cols = test_df.isnull().sum().sort_values(ascending=False)/len(test_df)*100\n",
    "test_null_cols[:40].plot(kind='bar', figsize=(14,10))\n",
    "plt.ylabel(\"% of null values in the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the columns with >60% values as NULL\n",
    "train_null_arr = np.array(train_null_cols[:34].index)\n",
    "test_null_arr = np.array(test_null_cols[:34].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether these NULL columns are same in number in both the cases\n",
    "len(train_null_arr), len(test_null_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are these columns same in both the cases. if yes, then we should get back a null set below\n",
    "set(train_null_arr).difference(test_null_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these columns\n",
    "train_df.drop(train_null_arr,axis=1,inplace=True)\n",
    "test_df.drop(test_null_arr,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset after dropping null columns : (8878, 294)\n",
      "The shape of the test dataset after dropping null columns : (4760, 293)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training dataset after dropping null columns : {}\".format(train_df.shape))\n",
    "print(\"The shape of the test dataset after dropping null columns : {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many columns have only one unique value?\n",
    "cols_with_one_val_train = np.array(train_df.nunique()[train_df.nunique()==1].index)\n",
    "cols_with_one_val_test = np.array(test_df.nunique()[test_df.nunique()==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_with_one_val_test), len(cols_with_one_val_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['application', 'languageisocode', 'originatingbody_type',\n",
       "       'documentcollectionid=CASELAW', 'documentcollectionid=JUDGMENTS',\n",
       "       'documentcollectionid=ENG', 'applicability=51', 'applicability=7',\n",
       "       'applicability=28', 'applicability=29', 'applicability=31',\n",
       "       'applicability=19', 'applicability=40', 'applicability=34',\n",
       "       'applicability=27', 'applicability=64', 'applicability=4',\n",
       "       'applicability=77', 'paragraphs=7-2', 'paragraphs=28-3',\n",
       "       'paragraphs=27-1-b', 'paragraphs=32-2', 'paragraphs=46-4'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_one_val_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['application', 'languageisocode', 'originatingbody_type',\n",
       "       'article=33', 'article=52', 'article=P13',\n",
       "       'documentcollectionid=CASELAW', 'documentcollectionid=JUDGMENTS',\n",
       "       'documentcollectionid=ENG', 'applicability=22', 'applicability=15',\n",
       "       'applicability=50', 'applicability=6', 'applicability=81',\n",
       "       'applicability=66', 'applicability=49', 'applicability=63',\n",
       "       'applicability=68', 'applicability=46', 'applicability=35',\n",
       "       'applicability=54', 'applicability=16', 'applicability=57',\n",
       "       'applicability=2', 'applicability=67', 'applicability=71',\n",
       "       'applicability=59', 'paragraphs=27-2', 'paragraphs=35-2',\n",
       "       'paragraphs=P1-4', 'paragraphs=56-1', 'paragraphs=P7-1-2',\n",
       "       'paragraphs=15-3', 'paragraphs=33', 'paragraphs=28-1-a',\n",
       "       'paragraphs=4-3', 'paragraphs=52', 'paragraphs=P13-1',\n",
       "       'paragraphs=P7-4-1', 'paragraphs=P4-3', 'paragraphs=29-1',\n",
       "       'paragraphs=28-1', 'paragraphs=P6-2', 'ccl_article=17',\n",
       "       'ccl_article=46', 'ccl_article=p12'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_one_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application',\n",
       " 'documentcollectionid=CASELAW',\n",
       " 'documentcollectionid=ENG',\n",
       " 'documentcollectionid=JUDGMENTS',\n",
       " 'languageisocode',\n",
       " 'originatingbody_type'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are these columns common in both the sets?\n",
    "set(cols_with_one_val_test).intersection(cols_with_one_val_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns with only one unique values in both the datasets\n",
    "cols_with_one_val = list(set(cols_with_one_val_test).intersection(cols_with_one_val_train))\n",
    "train_df.drop(cols_with_one_val, axis=1, inplace=True)\n",
    "test_df.drop(cols_with_one_val, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n",
      "train set :  [0]\n",
      "test set :  [0 1]\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# columns that have one unique val in training set but not in test set -> needs special attention\n",
    "one_val_train = ['applicability=51', 'applicability=7','applicability=28', 'applicability=29', 'applicability=31',\n",
    "                 'applicability=19', 'applicability=40', 'applicability=34','applicability=27', 'applicability=64', \n",
    "                 'applicability=4','applicability=77', 'paragraphs=7-2', 'paragraphs=28-3','paragraphs=27-1-b', \n",
    "                 'paragraphs=32-2', 'paragraphs=46-4']\n",
    "\n",
    "for col in one_val_train:\n",
    "    print(\"train set : \", train_df[col].unique())\n",
    "    print(\"test set : \", test_df[col].unique())\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "*********************\n",
      "col : applicability=51\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=51, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=7\n",
      "0    4758\n",
      "1       2\n",
      "Name: applicability=7, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=28\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=28, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=29\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=29, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=31\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=31, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=19\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=19, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=40\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=40, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=34\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=34, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=27\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=27, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=64\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=64, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=4\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=4, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=77\n",
      "0    4759\n",
      "1       1\n",
      "Name: applicability=77, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=7-2\n",
      "0    4758\n",
      "1       2\n",
      "Name: paragraphs=7-2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=28-3\n",
      "0    4759\n",
      "1       1\n",
      "Name: paragraphs=28-3, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=27-1-b\n",
      "0    4759\n",
      "1       1\n",
      "Name: paragraphs=27-1-b, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=32-2\n",
      "0    4759\n",
      "1       1\n",
      "Name: paragraphs=32-2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=46-4\n",
      "0    4759\n",
      "1       1\n",
      "Name: paragraphs=46-4, dtype: int64\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# since these columns are constant during training, it is better to remove them from both the datasets. But before\n",
    "# that let's apply value_counts on these columns in the test set\n",
    "\n",
    "print(\"Test set\")\n",
    "for col in one_val_train:\n",
    "    print(\"*********************\")\n",
    "    print(\"col : {}\".format(col))\n",
    "    print(test_df[col].value_counts())\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Therefore, it looks like these columns are constant 99% of the time even in the test set and we can safely \n",
    "# remove them.\n",
    "train_df.drop(one_val_train,axis=1,inplace=True)\n",
    "test_df.drop(one_val_train,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name :  article=33\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  article=52\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  article=P13\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=22\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=15\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=50\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=6\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=81\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=66\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=49\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=63\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=68\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=46\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=35\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=54\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=16\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=57\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=2\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=67\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=71\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  applicability=59\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=27-2\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=35-2\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=P1-4\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=56-1\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=P7-1-2\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=15-3\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=33\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=28-1-a\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=4-3\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=52\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=P13-1\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=P7-4-1\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=P4-3\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=29-1\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=28-1\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  paragraphs=P6-2\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  ccl_article=17\n",
      "train set :  [ 0 -1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  ccl_article=46\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n",
      "column name :  ccl_article=p12\n",
      "train set :  [0 1]\n",
      "test set :  [0]\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# columns that have one unique val in test set but not in training set -> we can keep these columns\n",
    "one_val_test = ['article=33', 'article=52', 'article=P13', 'applicability=22', 'applicability=15',\n",
    "                'applicability=50', 'applicability=6', 'applicability=81', 'applicability=66', 'applicability=49',\n",
    "                'applicability=63', 'applicability=68', 'applicability=46', 'applicability=35','applicability=54', \n",
    "                'applicability=16', 'applicability=57', 'applicability=2', 'applicability=67', 'applicability=71',\n",
    "                'applicability=59', 'paragraphs=27-2', 'paragraphs=35-2', 'paragraphs=P1-4', 'paragraphs=56-1', \n",
    "                'paragraphs=P7-1-2', 'paragraphs=15-3', 'paragraphs=33', 'paragraphs=28-1-a', 'paragraphs=4-3',\n",
    "                'paragraphs=52', 'paragraphs=P13-1', 'paragraphs=P7-4-1', 'paragraphs=P4-3', 'paragraphs=29-1',\n",
    "                'paragraphs=28-1', 'paragraphs=P6-2', 'ccl_article=17', 'ccl_article=46', 'ccl_article=p12']\n",
    "\n",
    "for col in one_val_test:\n",
    "    print(\"column name : \", col)\n",
    "    print(\"train set : \", train_df[col].unique())\n",
    "    print(\"test set : \", test_df[col].unique())\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.999887\n",
       "-1    0.000113\n",
       "Name: ccl_article=17, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column 'ccl_article=17' has two binary values as -1 and 0. Let's investigate it.\n",
    "train_df['ccl_article=17'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "Name: ccl_article=17, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['ccl_article=17'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be a mistake in entering value in the column 'ccl_article=17'. Let's drop this column as well\n",
    "train_df.drop('ccl_article=17',axis=1,inplace=True)\n",
    "test_df.drop('ccl_article=17',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "*********************\n",
      "col : article=33\n",
      "0    8877\n",
      "1       1\n",
      "Name: article=33, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : article=52\n",
      "0    8876\n",
      "1       2\n",
      "Name: article=52, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : article=P13\n",
      "0    8877\n",
      "1       1\n",
      "Name: article=P13, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=22\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=22, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=15\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=15, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=50\n",
      "0    8876\n",
      "1       2\n",
      "Name: applicability=50, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=6\n",
      "0    8876\n",
      "1       2\n",
      "Name: applicability=6, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=81\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=81, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=66\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=66, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=49\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=49, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=63\n",
      "0    8875\n",
      "1       3\n",
      "Name: applicability=63, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=68\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=68, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=46\n",
      "0    8876\n",
      "1       2\n",
      "Name: applicability=46, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=35\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=35, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=54\n",
      "0    8876\n",
      "1       2\n",
      "Name: applicability=54, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=16\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=16, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=57\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=57, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=2\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=67\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=67, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=71\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=71, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : applicability=59\n",
      "0    8877\n",
      "1       1\n",
      "Name: applicability=59, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=27-2\n",
      "0    8875\n",
      "1       3\n",
      "Name: paragraphs=27-2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=35-2\n",
      "0    8868\n",
      "1      10\n",
      "Name: paragraphs=35-2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=P1-4\n",
      "0    8876\n",
      "1       2\n",
      "Name: paragraphs=P1-4, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=56-1\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=56-1, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=P7-1-2\n",
      "0    8875\n",
      "1       3\n",
      "Name: paragraphs=P7-1-2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=15-3\n",
      "0    8875\n",
      "1       3\n",
      "Name: paragraphs=15-3, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=33\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=33, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=28-1-a\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=28-1-a, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=4-3\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=4-3, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=52\n",
      "0    8876\n",
      "1       2\n",
      "Name: paragraphs=52, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=P13-1\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=P13-1, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=P7-4-1\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=P7-4-1, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=P4-3\n",
      "0    8876\n",
      "1       2\n",
      "Name: paragraphs=P4-3, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=29-1\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=29-1, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=28-1\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=28-1, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : paragraphs=P6-2\n",
      "0    8877\n",
      "1       1\n",
      "Name: paragraphs=P6-2, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : ccl_article=46\n",
      "0    8877\n",
      "1       1\n",
      "Name: ccl_article=46, dtype: int64\n",
      "---------------------\n",
      "*********************\n",
      "col : ccl_article=p12\n",
      "0    8877\n",
      "1       1\n",
      "Name: ccl_article=p12, dtype: int64\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at distribution of categories in these columns in the training set\n",
    "print(\"Train set\")\n",
    "one_val_test.remove('ccl_article=17')\n",
    "for col in one_val_test:\n",
    "    print(\"*********************\")\n",
    "    print(\"col : {}\".format(col))\n",
    "    print(train_df[col].value_counts())\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, as we can see almost all the columns except 'paragraphs=35-2' has not more than 3 entries associated with \n",
    "# category=1. Even if the col 'paragraphs=35-2' has a very tiny fraction of category=1. So, we will drop these \n",
    "# columns from both the training and test sets as of now.\n",
    "\n",
    "train_df.drop(one_val_test,axis=1,inplace=True)\n",
    "test_df.drop(one_val_test,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set after dropping columns with constant values : (8878, 231)\n",
      "The shape of the test set after dropping columns with constant values : (4760, 230)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training set after dropping columns with constant values : {}\".format(train_df.shape))\n",
    "print(\"The shape of the test set after dropping columns with constant values : {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    8878\n",
      "dtype: int64\n",
      "--------------------------\n",
      "False    4760\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check whether there is any duplicate row in both the datasets\n",
    "print(train_df.duplicated().value_counts())\n",
    "print(\"--------------------------\")\n",
    "print(test_df.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now look at the cols with 'object' type\n",
    "obj_cols_train = train_df.select_dtypes(include='object')\n",
    "obj_cols_test = test_df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "['appno', 'country.alpha2', 'country.name', 'docname', 'doctypebranch', 'ecli', 'itemid', 'judgementdate', 'kpdate', 'originatingbody_name', 'parties.0', 'parties.1', 'respondent.0']\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Test set\n",
      "['appno', 'country.alpha2', 'country.name', 'docname', 'doctypebranch', 'ecli', 'itemid', 'judgementdate', 'kpdate', 'originatingbody_name', 'parties.0', 'parties.1', 'respondent.0']\n"
     ]
    }
   ],
   "source": [
    "# are columns with object type are same in both the datsets\n",
    "print(\"Train set\")\n",
    "print(list(obj_cols_train.columns))\n",
    "print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Test set\")\n",
    "print(list(obj_cols_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check these columns one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'appno'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : appno\n",
      "Total no. of unique values in the training set : 8799\n",
      "Total no. of unique values in the test set : 4760\n"
     ]
    }
   ],
   "source": [
    "print(\"col : appno\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['appno'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {}\".format(test_df['appno'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this feature is more likely to be same as that of fetaure like id with different value for each instance and is\n",
    "# not significant to train on. Let's drop it.\n",
    "train_df.drop('appno',axis=1,inplace=True)\n",
    "test_df.drop('appno',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'country.alpha2'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : country.alpha2\n",
      "Total no. of unique values in the training set : 46\n",
      "Total no. of unique values in the test set : 46 \n",
      "\n",
      "Train set :  ['ru' 'tr' 'si' 'ch' 'gr' 'pl' 'gb' 'hu' 'es' 'ua' 'me' 'cz' 'lt' 'az'\n",
      " 'md' 'mk' 'ro' 'rs' 'de' 'bg' 'al' 'at' 'hr' 'sk' 'it' 'fi' 'fr' 'se'\n",
      " 'no' 'is' 'am' 'mt' 'be' 'cy' 'ge' 'pt' 'dk' 'lv' 'ee' 'ba' 'nl' 'ie'\n",
      " 'li' 'sm' 'lu' 'ad'] \n",
      "\n",
      "Test set :  ['mk' 'ua' 'ie' 'ru' 'bg' 'pl' 'gr' 'hu' 'de' 'at' 'hr' 'lt' 'md' 'si'\n",
      " 'fi' 'tr' 'ro' 'cz' 'dk' 'gb' 'al' 'se' 'nl' 'rs' 'sk' 'is' 'lv' 'cy'\n",
      " 'ge' 'it' 'ch' 'mt' 'es' 'pt' 'ba' 'ee' 'az' 'am' 'sm' 'no' 'be' 'me'\n",
      " 'fr' 'lu' 'ad' 'li'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : country.alpha2\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['country.alpha2'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['country.alpha2'].nunique()))\n",
    "print(\"Train set : \",train_df['country.alpha2'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['country.alpha2'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# do categories present in both of these files same?\n",
    "print(set(train_df['country.alpha2'].unique()).difference(test_df['country.alpha2'].unique()))\n",
    "print(set(test_df['country.alpha2'].unique()).difference(train_df['country.alpha2'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "ru    0.185515\n",
      "ua    0.105091\n",
      "tr    0.097770\n",
      "pl    0.069498\n",
      "hu    0.041000\n",
      "ro    0.037734\n",
      "bg    0.034242\n",
      "gb    0.033904\n",
      "hr    0.028723\n",
      "at    0.026245\n",
      "sk    0.025569\n",
      "it    0.025118\n",
      "md    0.024668\n",
      "si    0.023541\n",
      "de    0.022077\n",
      "fr    0.019374\n",
      "az    0.015093\n",
      "lt    0.014643\n",
      "rs    0.014305\n",
      "fi    0.013066\n",
      "mk    0.012390\n",
      "gr    0.010926\n",
      "nl    0.010813\n",
      "am    0.009687\n",
      "ch    0.008223\n",
      "mt    0.007885\n",
      "se    0.007547\n",
      "lv    0.007434\n",
      "ge    0.006871\n",
      "cy    0.006195\n",
      "cz    0.005745\n",
      "pt    0.005745\n",
      "ba    0.005632\n",
      "be    0.005407\n",
      "es    0.005294\n",
      "ee    0.004956\n",
      "al    0.004731\n",
      "me    0.004393\n",
      "no    0.004055\n",
      "dk    0.002591\n",
      "ie    0.002365\n",
      "is    0.001577\n",
      "sm    0.000788\n",
      "lu    0.000788\n",
      "li    0.000676\n",
      "ad    0.000113\n",
      "Name: country.alpha2, dtype: float64\n",
      "\n",
      "\n",
      "Test Set:\n",
      "ru    0.205462\n",
      "tr    0.095168\n",
      "ua    0.090966\n",
      "pl    0.074370\n",
      "hu    0.041597\n",
      "ro    0.039286\n",
      "gb    0.034034\n",
      "bg    0.033193\n",
      "hr    0.028151\n",
      "md    0.027941\n",
      "sk    0.025210\n",
      "at    0.023950\n",
      "si    0.023109\n",
      "it    0.020588\n",
      "de    0.019118\n",
      "rs    0.017227\n",
      "lt    0.015126\n",
      "az    0.013655\n",
      "gr    0.013025\n",
      "fi    0.012605\n",
      "fr    0.012185\n",
      "mk    0.011765\n",
      "lv    0.011345\n",
      "se    0.010084\n",
      "am    0.009454\n",
      "nl    0.008613\n",
      "ba    0.008193\n",
      "ge    0.007983\n",
      "ch    0.007143\n",
      "al    0.006513\n",
      "cz    0.006092\n",
      "mt    0.005882\n",
      "be    0.005042\n",
      "me    0.004622\n",
      "cy    0.004202\n",
      "pt    0.003992\n",
      "es    0.003992\n",
      "no    0.003782\n",
      "dk    0.003571\n",
      "ee    0.003571\n",
      "is    0.003151\n",
      "ie    0.002521\n",
      "sm    0.001261\n",
      "li    0.000630\n",
      "lu    0.000420\n",
      "ad    0.000210\n",
      "Name: country.alpha2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# what is the distribution of different categories?\n",
    "print(\"Train Set:\")\n",
    "print(train_df['country.alpha2'].value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "print(\"Test Set:\")\n",
    "print(test_df['country.alpha2'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'country.name'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : country.name\n",
      "Total no. of unique values in the training set : 46\n",
      "Total no. of unique values in the test set : 46 \n",
      "\n",
      "Train set :  ['Russian Federation' 'Turkey' 'Slovenia' 'Switzerland' 'Greece' 'Poland'\n",
      " 'United Kingdom' 'Hungary' 'Spain' 'Ukraine' 'Montenegro' 'Czechia'\n",
      " 'Lithuania' 'Azerbaijan' 'Moldova, Republic of' 'North Macedonia'\n",
      " 'Romania' 'Serbia' 'Germany' 'Bulgaria' 'Albania' 'Austria' 'Croatia'\n",
      " 'Slovakia' 'Italy' 'Finland' 'France' 'Sweden' 'Norway' 'Iceland'\n",
      " 'Armenia' 'Malta' 'Belgium' 'Cyprus' 'Georgia' 'Portugal' 'Denmark'\n",
      " 'Latvia' 'Estonia' 'Bosnia and Herzegovina' 'Netherlands' 'Ireland'\n",
      " 'Liechtenstein' 'San Marino' 'Luxembourg' 'Andorra'] \n",
      "\n",
      "Test set :  ['North Macedonia' 'Ukraine' 'Ireland' 'Russian Federation' 'Bulgaria'\n",
      " 'Poland' 'Greece' 'Hungary' 'Germany' 'Austria' 'Croatia' 'Lithuania'\n",
      " 'Moldova, Republic of' 'Slovenia' 'Finland' 'Turkey' 'Romania' 'Czechia'\n",
      " 'Denmark' 'United Kingdom' 'Albania' 'Sweden' 'Netherlands' 'Serbia'\n",
      " 'Slovakia' 'Iceland' 'Latvia' 'Cyprus' 'Georgia' 'Italy' 'Switzerland'\n",
      " 'Malta' 'Spain' 'Portugal' 'Bosnia and Herzegovina' 'Estonia'\n",
      " 'Azerbaijan' 'Armenia' 'San Marino' 'Norway' 'Belgium' 'Montenegro'\n",
      " 'France' 'Luxembourg' 'Andorra' 'Liechtenstein'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : country.name\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['country.name'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['country.name'].nunique()))\n",
    "print(\"Train set : \",train_df['country.name'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['country.name'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# do categories present in both of these files same?\n",
    "print(set(train_df['country.name'].unique()).difference(test_df['country.name'].unique()))\n",
    "print(set(test_df['country.name'].unique()).difference(train_df['country.name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually, country.alpha2 and country.name are the same feature. We can drop one of them as of now. Let's drop \n",
    "# country.name.\n",
    "train_df.drop(\"country.name\",axis=1,inplace=True)\n",
    "test_df.drop(\"country.name\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'docname'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : docname\n",
      "Total no. of unique values in the training set : 8682\n",
      "Total no. of unique values in the test set : 4727 \n",
      "\n",
      "Train set :  ['CASE OF KOKOSHKINA v. RUSSIA' 'CASE OF ÖZCAN v. TURKEY'\n",
      " 'CASE OF DANIJEL PEČNIK v. SLOVENIA' ... 'CASE OF BABUSHKIN v. RUSSIA'\n",
      " 'CASE OF BRUALLA GÓMEZ DE LA TORRE v. SPAIN' 'CASE OF TUR v. POLAND'] \n",
      "\n",
      "Test set :  ['CASE OF CAMINSKI v. \"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"'\n",
      " 'CASE OF KUSHCH v. UKRAINE' 'CASE OF O. v. IRELAND' ...\n",
      " 'CASE OF PASCAL v. ROMANIA' 'CASE OF DAOUKOPOULOS v. GREECE'\n",
      " 'CASE OF VOGLREITER v. AUSTRIA'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : docname\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['docname'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['docname'].nunique()))\n",
    "print(\"Train set : \",train_df['docname'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['docname'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CASE OF KOKOSHKINA v. RUSSIA', 'CASE OF ÖZCAN v. TURKEY',\n",
       "       'CASE OF DANIJEL PEČNIK v. SLOVENIA',\n",
       "       'CASE OF PALANCI v. SWITZERLAND',\n",
       "       'CASE OF AMANAT ILYASOVA AND OTHERS v. RUSSIA'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['docname'].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>docname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru</td>\n",
       "      <td>CASE OF KOKOSHKINA v. RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>CASE OF ÖZCAN v. TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si</td>\n",
       "      <td>CASE OF DANIJEL PEČNIK v. SLOVENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch</td>\n",
       "      <td>CASE OF PALANCI v. SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>CASE OF AMANAT ILYASOVA AND OTHERS v. RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873</th>\n",
       "      <td>ua</td>\n",
       "      <td>CASE OF RASHITOV AND OTHERS v. UKRAINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>ru</td>\n",
       "      <td>CASE OF URMANOV v. RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8875</th>\n",
       "      <td>ru</td>\n",
       "      <td>CASE OF BABUSHKIN v. RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>es</td>\n",
       "      <td>CASE OF BRUALLA GÓMEZ DE LA TORRE v. SPAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>pl</td>\n",
       "      <td>CASE OF TUR v. POLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country.alpha2                                       docname\n",
       "0                ru                  CASE OF KOKOSHKINA v. RUSSIA\n",
       "1                tr                       CASE OF ÖZCAN v. TURKEY\n",
       "2                si            CASE OF DANIJEL PEČNIK v. SLOVENIA\n",
       "3                ch                CASE OF PALANCI v. SWITZERLAND\n",
       "4                ru  CASE OF AMANAT ILYASOVA AND OTHERS v. RUSSIA\n",
       "...             ...                                           ...\n",
       "8873             ua        CASE OF RASHITOV AND OTHERS v. UKRAINE\n",
       "8874             ru                     CASE OF URMANOV v. RUSSIA\n",
       "8875             ru                   CASE OF BABUSHKIN v. RUSSIA\n",
       "8876             es    CASE OF BRUALLA GÓMEZ DE LA TORRE v. SPAIN\n",
       "8877             pl                         CASE OF TUR v. POLAND\n",
       "\n",
       "[8878 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['country.alpha2', 'docname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this feature contains two pieces of information - person name and the country name against which he/she filed a \n",
    "# case. The country information is already present in the feature country.alpha2 and name of a person is more similar\n",
    "# to ids. So, we can drop this feature as well.\n",
    "\n",
    "train_df.drop('docname', axis=1,inplace=True)\n",
    "test_df.drop('docname', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'doctypebranch'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : doctypebranch\n",
      "Total no. of unique values in the training set : 3\n",
      "Total no. of unique values in the test set : 3 \n",
      "\n",
      "Train set :  ['CHAMBER' 'COMMITTEE' 'GRANDCHAMBER'] \n",
      "\n",
      "Test set :  ['COMMITTEE' 'CHAMBER' 'GRANDCHAMBER'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : doctypebranch\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['doctypebranch'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['doctypebranch'].nunique()))\n",
    "print(\"Train set : \",train_df['doctypebranch'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['doctypebranch'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'ecli'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : ecli\n",
      "Total no. of unique values in the training set : 8878\n",
      "Total no. of unique values in the test set : 4760 \n",
      "\n",
      "Train set :  ['ECLI:CE:ECHR:2009:0528JUD000205208' 'ECLI:CE:ECHR:2018:0710JUD000472807'\n",
      " 'ECLI:CE:ECHR:2012:1018JUD004413506' ...\n",
      " 'ECLI:CE:ECHR:2007:1018JUD006725301' 'ECLI:CE:ECHR:1997:1219JUD002673795'\n",
      " 'ECLI:CE:ECHR:2007:1023JUD002169505'] \n",
      "\n",
      "Test set :  ['ECLI:CE:ECHR:2011:0224JUD000119404' 'ECLI:CE:ECHR:2015:1203JUD005386511'\n",
      " 'ECLI:CE:ECHR:2012:0119JUD004383807' ...\n",
      " 'ECLI:CE:ECHR:2012:0417JUD000080509' 'ECLI:CE:ECHR:2018:0712JUD004471116'\n",
      " 'ECLI:CE:ECHR:2019:0919JUD002115518'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : ecli\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['ecli'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['ecli'].nunique()))\n",
    "print(\"Train set : \",train_df['ecli'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['ecli'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature is basically unique id associated with a case and can be dropped.\n",
    "train_df.drop('ecli',axis=1,inplace=True)\n",
    "test_df.drop('ecli',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'itemid'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : itemid\n",
      "Total no. of unique values in the training set : 8878\n",
      "Total no. of unique values in the test set : 4760 \n",
      "\n",
      "Train set :  ['001-92699' '001-184490' '001-113810' ... '001-82818' '001-58127'\n",
      " '001-82921'] \n",
      "\n",
      "Test set :  ['001-103613' '001-158963' '001-108659' ... '001-110382' '001-184485'\n",
      " '001-195866'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : itemid\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['itemid'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['itemid'].nunique()))\n",
    "print(\"Train set : \",train_df['itemid'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['itemid'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again a feature similar to ids and hence dropped.\n",
    "train_df.drop('itemid',axis=1,inplace=True)\n",
    "test_df.drop('itemid',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'judgementdate'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : judgementdate\n",
      "Total no. of unique values in the training set : 1906\n",
      "Total no. of unique values in the test set : 1584 \n",
      "\n",
      "Train set :  ['28/05/2009' '10/07/2018' '18/10/2012' ... '29/10/2013' '04/12/2015'\n",
      " '19/12/1997'] \n",
      "\n",
      "Test set :  ['24/02/2011' '03/12/2015' '19/01/2012' ... '23/10/1990' '10/03/2009'\n",
      " '22/07/1999'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : judgementdate\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['judgementdate'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['judgementdate'].nunique()))\n",
    "print(\"Train set : \",train_df['judgementdate'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['judgementdate'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date like feature. We will come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'kpdate'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : kpdate\n",
      "Total no. of unique values in the training set : 1906\n",
      "Total no. of unique values in the test set : 1584 \n",
      "\n",
      "Train set :  ['28/05/2009' '10/07/2018' '18/10/2012' ... '29/10/2013' '04/12/2015'\n",
      " '19/12/1997'] \n",
      "\n",
      "Test set :  ['24/02/2011' '03/12/2015' '19/01/2012' ... '23/10/1990' '10/03/2009'\n",
      " '22/07/1999'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : kpdate\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['kpdate'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['kpdate'].nunique()))\n",
    "print(\"Train set : \",train_df['kpdate'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['kpdate'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgementdate</th>\n",
       "      <th>kpdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/05/2009</td>\n",
       "      <td>28/05/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/07/2018</td>\n",
       "      <td>10/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/10/2012</td>\n",
       "      <td>18/10/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25/03/2014</td>\n",
       "      <td>25/03/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/10/2009</td>\n",
       "      <td>01/10/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/04/2002</td>\n",
       "      <td>11/04/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20/06/2006</td>\n",
       "      <td>20/06/2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27/11/2007</td>\n",
       "      <td>27/11/2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>01/03/2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02/12/2008</td>\n",
       "      <td>02/12/2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  judgementdate      kpdate\n",
       "0    28/05/2009  28/05/2009\n",
       "1    10/07/2018  10/07/2018\n",
       "2    18/10/2012  18/10/2012\n",
       "3    25/03/2014  25/03/2014\n",
       "4    01/10/2009  01/10/2009\n",
       "5    11/04/2002  11/04/2002\n",
       "6    20/06/2006  20/06/2006\n",
       "7    27/11/2007  27/11/2007\n",
       "8    01/03/2001  01/03/2001\n",
       "9    02/12/2008  02/12/2008"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like features 'judgementdate' and 'kpdate' represent the same thing.\n",
    "train_df[['judgementdate','kpdate']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgementdate</th>\n",
       "      <th>kpdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/02/2011</td>\n",
       "      <td>24/02/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/12/2015</td>\n",
       "      <td>03/12/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19/01/2012</td>\n",
       "      <td>19/01/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/2013</td>\n",
       "      <td>04/07/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26/02/2009</td>\n",
       "      <td>26/02/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12/03/2009</td>\n",
       "      <td>12/03/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27/11/2014</td>\n",
       "      <td>27/11/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12/02/2009</td>\n",
       "      <td>12/02/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23/10/2012</td>\n",
       "      <td>23/10/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13/01/2011</td>\n",
       "      <td>13/01/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  judgementdate      kpdate\n",
       "0    24/02/2011  24/02/2011\n",
       "1    03/12/2015  03/12/2015\n",
       "2    19/01/2012  19/01/2012\n",
       "3    04/07/2013  04/07/2013\n",
       "4    26/02/2009  26/02/2009\n",
       "5    12/03/2009  12/03/2009\n",
       "6    27/11/2014  27/11/2014\n",
       "7    12/02/2009  12/02/2009\n",
       "8    23/10/2012  23/10/2012\n",
       "9    13/01/2011  13/01/2011"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['judgementdate','kpdate']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So these two are duplicate features and we drop one of them.\n",
    "train_df.drop('kpdate',axis=1,inplace=True)\n",
    "test_df.drop('kpdate',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'originatingbody_name'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : originatingbody_name\n",
      "Total no. of unique values in the training set : 13\n",
      "Total no. of unique values in the test set : 13 \n",
      "\n",
      "Train set :  ['First Section' 'Second Section Committee' 'Fith Section'\n",
      " 'Second Section' 'Fourth Section' 'Chamber' 'Fourth Section Committee'\n",
      " 'Fith Section Committee' 'Third Section Committee' 'Third Section'\n",
      " 'First Section Committee' 'Grand Chamber' 'Plenary'] \n",
      "\n",
      "Test set :  ['Fith Section Committee' 'Fith Section' 'First Section' 'Fourth Section'\n",
      " 'First Section Committee' 'Fourth Section Committee'\n",
      " 'Third Section Committee' 'Second Section Committee' 'Third Section'\n",
      " 'Second Section' 'Grand Chamber' 'Chamber' 'Plenary'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : originatingbody_name\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['originatingbody_name'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['originatingbody_name'].nunique()))\n",
    "print(\"Train set : \",train_df['originatingbody_name'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['originatingbody_name'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# are all categories same in both the datasets?\n",
    "print(set(train_df['originatingbody_name'].unique()).difference(test_df['originatingbody_name']))\n",
    "print(set(test_df['originatingbody_name'].unique()).difference(train_df['originatingbody_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'parties.0'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : parties.0\n",
      "Total no. of unique values in the training set : 8361\n",
      "Total no. of unique values in the test set : 4624 \n",
      "\n",
      "Train set :  ['KOKOSHKINA' 'ÖZCAN' 'DANIJEL PEČNIK' ... 'BABUSHKIN'\n",
      " 'BRUALLA GÓMEZ DE LA TORRE' 'TUR'] \n",
      "\n",
      "Test set :  ['CAMINSKI' 'KUSHCH' 'O.' ... 'PASCAL' 'DAOUKOPOULOS' 'VOGLREITER'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : parties.0\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['parties.0'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['parties.0'].nunique()))\n",
    "print(\"Train set : \",train_df['parties.0'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['parties.0'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we go back to the dropped feature 'docname', we can associate the feature 'parties.0'  most likely to represent the name\n",
    "# of person filing the case. Since, we have dropped this info earlier, we will drop it this time also.\n",
    "\n",
    "train_df.drop('parties.0',axis=1,inplace=True)\n",
    "test_df.drop('parties.0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'parties.1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : parties.1\n",
      "Total no. of unique values in the training set : 93\n",
      "Total no. of unique values in the test set : 76 \n",
      "\n",
      "Train set :  ['RUSSIA' 'TURKEY' 'SLOVENIA' 'SWITZERLAND' 'GREECE' 'POLAND'\n",
      " 'THE UNITED KINGDOM' 'HUNGARY' 'SPAIN' 'UKRAINE' 'MONTENEGRO'\n",
      " 'THE CZECH REPUBLIC [Extracts]' 'LITHUANIA' 'AZERBAIJAN' 'MOLDOVA'\n",
      " '\"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"' 'ROMANIA' 'SERBIA'\n",
      " 'GERMANY' 'BULGARIA' 'ALBANIA' 'AUSTRIA' 'CROATIA' 'SLOVAKIA' 'ITALY'\n",
      " 'FINLAND' 'FRANCE [Extracts]' 'SWEDEN' 'NORWAY' 'FRANCE' 'ICELAND'\n",
      " 'ARMENIA' 'MALTA' 'BELGIUM [Extracts]' 'BELGIUM' 'CYPRUS' 'GEORGIA'\n",
      " 'THE REPUBLIC OF MOLDOVA' 'PORTUGAL' 'THE CZECH REPUBLIC' 'DENMARK'\n",
      " 'LATVIA' 'ESTONIA' 'BOSNIA AND HERZEGOVINA' 'THE NETHERLANDS'\n",
      " 'THE REPUBLIC OF MOLDOVA AND RUSSIA' 'SAN MARINO AND ITALY'\n",
      " 'ITALY [Extracts]' 'IRELAND' 'ROMANIA [Extracts]' 'NORTH MACEDONIA'\n",
      " 'BULGARIA [Extracts]' 'LIECHTENSTEIN' 'AZERBAIJAN AND TURKEY'\n",
      " 'UKRAINE [Extracts]' 'ITALIE' 'MONTENEGRO AND SERBIA'\n",
      " 'ROMANIA AND BULGARIA' nan '\"THE FORMER YOUGOSLAV REPUBLIC OF MACEDONIA\"'\n",
      " 'TURKEY [Extracts]' 'SPAIN [Extracts]' 'FRANCE AND SPAIN'\n",
      " 'LITHUANIA AND SWEDEN' 'SAN MARINO' 'GERMANY [Extracts]'\n",
      " 'SLOVAKIA AND UKRAINE' 'ROMANIA AND HUNGARY' 'GEORGIA AND RUSSIA'\n",
      " 'CYPRUS AND TURKEY' 'RUSSIA AND UKRAINE AND UDALTSOV' 'LUXEMBOURG'\n",
      " 'GREECE [Extracts]' 'ARMENIA AND MOLDOVA' 'BELGIUM AND GREECE'\n",
      " 'LATVIA [Extracts]'\n",
      " 'BULGARIA - [English Translation] by European Roma Rights Centre \"ERRC\"'\n",
      " 'ANDORRA' 'MOLDOVA AND RUSSIA' 'CYPRUS AND RUSSIA' 'HUNGARY AND SLOVAKIA'\n",
      " 'HUNGARY NO.4'\n",
      " 'BOSNIA AND HERZEGOVINA, CROATIA, SERBIA, SLOVENIA AND \"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"'\n",
      " 'SLOVENIE' 'SLOVENIA (No. 2)'\n",
      " 'GREECE - [English Translation] by European Roma Rights Centre \"ERRC\"'\n",
      " 'RUSSIA AND UKRAINE' 'SAN MARINO [Extracts]' 'POLAND AND GERMANY'\n",
      " 'PORTUGAL [Extracts]' 'ALBANIA AND ITALY' 'ITALY (No. 2) [Extracts]'\n",
      " 'SWITZERLAND (No. 2) [Extracts]' 'SWITZERLAND [Extracts]'] \n",
      "\n",
      "Test set :  ['\"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"' 'UKRAINE' 'IRELAND'\n",
      " 'RUSSIA' 'BULGARIA' 'POLAND' 'GREECE' 'HUNGARY' 'GERMANY' 'AUSTRIA'\n",
      " 'CROATIA' 'LITHUANIA' 'MOLDOVA' 'SLOVENIA' 'FINLAND' 'TURKEY' 'ROMANIA'\n",
      " 'THE REPUBLIC OF MOLDOVA' 'THE CZECH REPUBLIC' 'DENMARK'\n",
      " 'THE UNITED KINGDOM' 'ALBANIA' 'SWEDEN' 'THE NETHERLANDS' 'SERBIA'\n",
      " 'SLOVAKIA' 'ICELAND' 'LATVIA' 'CYPRUS' 'NORTH MACEDONIA' 'GEORGIA'\n",
      " 'ITALY' 'SWITZERLAND' 'MALTA' 'SPAIN' 'PORTUGAL' 'BOSNIA AND HERZEGOVINA'\n",
      " 'ESTONIA' 'AZERBAIJAN' 'ARMENIA' 'TURKEY [Extracts]' 'SAN MARINO'\n",
      " 'NORWAY' 'SLOVENIA AND AUSTRIA' 'BELGIUM' 'MONTENEGRO' 'FRANCE' nan\n",
      " 'BELGIUM [Extracts]' 'GREECE [Extracts]'\n",
      " 'THE REPUBLIC OF MOLDOVA AND RUSSIA' 'THE CZECH REPUBLIC [Extracts]'\n",
      " 'FRANCE [Extracts]' 'GERMANY (No. 2)' 'ITALY [Extracts]'\n",
      " 'THE REPUBLIC OF MOLDOVA, RUSSIA AND UKRAINE' 'ROMANIA [Extracts]'\n",
      " 'SLOVENIE' 'HUNGARY AND GREECE' 'NETHERLANDS'\n",
      " 'BOSNIA AND HERZEGOVINA, CROATIA, SERBIA, SLOVENIA AND \"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"'\n",
      " 'SWITZERLAND [Extracts]' 'LUXEMBOURG' 'HUNGARY AND ITALY' 'ANDORRA'\n",
      " 'GREECE AND GERMANY' 'LIECHTENSTEIN' 'MONTENEGRO AND SERBIA'\n",
      " 'AZERBAIJAN AND HUNGARY' 'ALBANIA AND ITALY' 'ITALY AND BULGARIA'\n",
      " 'TURKEY (No. 2) [Extracts]'\n",
      " 'GREECE - [English Translation] by European Roma Rights Centre \"ERRC\"'\n",
      " 'ROMANIA AND THE UNITED KINGDOM' 'GREECE (No. 2) [Extracts]'\n",
      " 'POLAND AND GREECE' 'AUSTRIA (No. 3)'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : parties.1\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['parties.1'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['parties.1'].nunique()))\n",
    "print(\"Train set : \",train_df['parties.1'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['parties.1'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>parties.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si</td>\n",
       "      <td>SLOVENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gr</td>\n",
       "      <td>GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pl</td>\n",
       "      <td>POLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gb</td>\n",
       "      <td>THE UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hu</td>\n",
       "      <td>HUNGARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tr</td>\n",
       "      <td>TURKEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country.alpha2           parties.1\n",
       "0             ru              RUSSIA\n",
       "1             tr              TURKEY\n",
       "2             si            SLOVENIA\n",
       "3             ch         SWITZERLAND\n",
       "4             ru              RUSSIA\n",
       "5             gr              GREECE\n",
       "6             pl              POLAND\n",
       "7             gb  THE UNITED KINGDOM\n",
       "8             hu             HUNGARY\n",
       "9             tr              TURKEY"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This feature seems to represent country names and might be duplicate with country.alpha2\n",
    "\n",
    "train_df[['country.alpha2','parties.1']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>parties.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mk</td>\n",
       "      <td>\"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ua</td>\n",
       "      <td>UKRAINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ie</td>\n",
       "      <td>IRELAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUSSIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country.alpha2                                    parties.1\n",
       "0             mk  \"THE FORMER YUGOSLAV REPUBLIC OF MACEDONIA\"\n",
       "1             ua                                      UKRAINE\n",
       "2             ie                                      IRELAND\n",
       "3             ru                                       RUSSIA\n",
       "4             ru                                       RUSSIA"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['country.alpha2','parties.1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our guess is right! We drop this feature.\n",
    "\n",
    "train_df.drop('parties.1',axis=1,inplace=True)\n",
    "test_df.drop('parties.1',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'respondent.0'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col : respondent.0\n",
      "Total no. of unique values in the training set : 46\n",
      "Total no. of unique values in the test set : 46 \n",
      "\n",
      "Train set :  ['RUS' 'TUR' 'SVN' 'CHE' 'GRC' 'POL' 'GBR' 'HUN' 'ESP' 'UKR' 'MNE' 'CZE'\n",
      " 'LTU' 'AZE' 'MDA' 'MKD' 'ROU' 'SRB' 'DEU' 'BGR' 'ALB' 'AUT' 'HRV' 'SVK'\n",
      " 'ITA' 'FIN' 'FRA' 'SWE' 'NOR' 'ISL' 'ARM' 'MLT' 'BEL' 'CYP' 'GEO' 'PRT'\n",
      " 'DNK' 'LVA' 'EST' 'BIH' 'NLD' 'IRL' 'LIE' 'SMR' 'LUX' 'AND'] \n",
      "\n",
      "Test set :  ['MKD' 'UKR' 'IRL' 'RUS' 'BGR' 'POL' 'GRC' 'HUN' 'DEU' 'AUT' 'HRV' 'LTU'\n",
      " 'MDA' 'SVN' 'FIN' 'TUR' 'ROU' 'CZE' 'DNK' 'GBR' 'ALB' 'SWE' 'NLD' 'SRB'\n",
      " 'SVK' 'ISL' 'LVA' 'CYP' 'GEO' 'ITA' 'CHE' 'MLT' 'ESP' 'PRT' 'BIH' 'EST'\n",
      " 'AZE' 'ARM' 'SMR' 'NOR' 'BEL' 'MNE' 'FRA' 'LUX' 'AND' 'LIE'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"col : respondent.0\")\n",
    "print(\"Total no. of unique values in the training set : {}\".format(train_df['respondent.0'].nunique()))\n",
    "print(\"Total no. of unique values in the test set : {} \\n\".format(test_df['respondent.0'].nunique()))\n",
    "print(\"Train set : \",train_df['respondent.0'].unique(),\"\\n\")\n",
    "print(\"Test set : \",test_df['respondent.0'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>respondent.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>TUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si</td>\n",
       "      <td>SVN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gr</td>\n",
       "      <td>GRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pl</td>\n",
       "      <td>POL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gb</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hu</td>\n",
       "      <td>HUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tr</td>\n",
       "      <td>TUR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country.alpha2 respondent.0\n",
       "0             ru          RUS\n",
       "1             tr          TUR\n",
       "2             si          SVN\n",
       "3             ch          CHE\n",
       "4             ru          RUS\n",
       "5             gr          GRC\n",
       "6             pl          POL\n",
       "7             gb          GBR\n",
       "8             hu          HUN\n",
       "9             tr          TUR"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again this info is likely to be same as the feature 'country.alpha2'\n",
    "train_df[['country.alpha2','respondent.0']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country.alpha2</th>\n",
       "      <th>respondent.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mk</td>\n",
       "      <td>MKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ua</td>\n",
       "      <td>UKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ie</td>\n",
       "      <td>IRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ru</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ua</td>\n",
       "      <td>UKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bg</td>\n",
       "      <td>BGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pl</td>\n",
       "      <td>POL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gr</td>\n",
       "      <td>GRC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country.alpha2 respondent.0\n",
       "0             mk          MKD\n",
       "1             ua          UKR\n",
       "2             ie          IRL\n",
       "3             ru          RUS\n",
       "4             ru          RUS\n",
       "5             ru          RUS\n",
       "6             ua          UKR\n",
       "7             bg          BGR\n",
       "8             pl          POL\n",
       "9             gr          GRC"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['country.alpha2','respondent.0']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hence we drop it.\n",
    "train_df.drop('respondent.0',axis=1,inplace=True)\n",
    "test_df.drop('respondent.0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country.alpha2', 'doctypebranch', 'judgementdate',\n",
       "       'originatingbody_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining cols with 'object' type\n",
    "final_obj_cols = train_df.select_dtypes(include='object').columns\n",
    "final_obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set after dropping categorical features : (8878, 222)\n",
      "The shape of the test set after dropping categorical features : (4760, 221)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training set after dropping categorical features : {}\".format(train_df.shape))\n",
    "print(\"The shape of the test set after dropping categorical features : {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# let's look at the mixed data type features now. Since, we have dropped quite a few cols already, let's first \n",
    "# check whether these features are still present in the respective datasets.\n",
    "\n",
    "print([col for col in mixed_cols_train if col in train_df.columns])\n",
    "print([col for col in mixed_cols_test if col in test_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>separateopinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8875</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8878 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      separateopinion\n",
       "0               False\n",
       "1               False\n",
       "2                True\n",
       "3                True\n",
       "4               False\n",
       "...               ...\n",
       "8873            False\n",
       "8874            False\n",
       "8875            False\n",
       "8876            False\n",
       "8877            False\n",
       "\n",
       "[8878 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so, we have already removed these features from our dataset. Let's look at some non-categorical features.\n",
    "train_df.select_dtypes(include='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>separateopinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4760 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      separateopinion\n",
       "0               False\n",
       "1               False\n",
       "2               False\n",
       "3               False\n",
       "4               False\n",
       "...               ...\n",
       "4755            False\n",
       "4756            False\n",
       "4757            False\n",
       "4758            False\n",
       "4759            False\n",
       "\n",
       "[4760 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.select_dtypes(include='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert this as follows : True->1, False->0.\n",
    "train_df['separateopinion'] = train_df['separateopinion'].apply(lambda x:1 if x is True else 0)\n",
    "test_df['separateopinion'] = test_df['separateopinion'].apply(lambda x:1 if x is True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>685.417419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2641.901855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>942.213440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1121.770142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.821594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873</th>\n",
       "      <td>2424.463379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>1698.433228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8875</th>\n",
       "      <td>607.506531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>362.514832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>608.091614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8878 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank\n",
       "0      685.417419\n",
       "1     2641.901855\n",
       "2      942.213440\n",
       "3     1121.770142\n",
       "4      704.821594\n",
       "...           ...\n",
       "8873  2424.463379\n",
       "8874  1698.433228\n",
       "8875   607.506531\n",
       "8876   362.514832\n",
       "8877   608.091614\n",
       "\n",
       "[8878 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.select_dtypes(include='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>794.766724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1448.891235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>868.238831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024.145508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>672.862183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>1678.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>1161.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>892.368225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>2646.512939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>4270.748047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4760 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank\n",
       "0      794.766724\n",
       "1     1448.891235\n",
       "2      868.238831\n",
       "3     1024.145508\n",
       "4      672.862183\n",
       "...           ...\n",
       "4755  1678.799805\n",
       "4756  1161.929688\n",
       "4757   892.368225\n",
       "4758  2646.512939\n",
       "4759  4270.748047\n",
       "\n",
       "[4760 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.select_dtypes(include='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in mind, this feature m ght require scaling in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originatingbody</th>\n",
       "      <th>respondentOrderEng</th>\n",
       "      <th>separateopinion</th>\n",
       "      <th>sharepointid</th>\n",
       "      <th>typedescription</th>\n",
       "      <th>article=3</th>\n",
       "      <th>article=6</th>\n",
       "      <th>article=P1</th>\n",
       "      <th>article=5</th>\n",
       "      <th>article=8</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_article=5</th>\n",
       "      <th>ccl_article=6</th>\n",
       "      <th>ccl_article=7</th>\n",
       "      <th>ccl_article=8</th>\n",
       "      <th>ccl_article=9</th>\n",
       "      <th>ccl_article=p1</th>\n",
       "      <th>ccl_article=p4</th>\n",
       "      <th>ccl_article=p6</th>\n",
       "      <th>ccl_article=p7</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>349418</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>476616</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>373194</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>392525</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>423100</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873</th>\n",
       "      <td>29</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>473530</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>456937</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8875</th>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>340823</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>443927</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>343850</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8878 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      originatingbody  respondentOrderEng  separateopinion  sharepointid  \\\n",
       "0                   4                  38                0        349418   \n",
       "1                  26                  47                0        476616   \n",
       "2                  23                  43                1        373194   \n",
       "3                   5                  46                1        392525   \n",
       "4                   4                  38                0        423100   \n",
       "...               ...                 ...              ...           ...   \n",
       "8873               29                  48                0        473530   \n",
       "8874               27                  38                0        456937   \n",
       "8875                6                  38                0        340823   \n",
       "8876                9                  44                0        443927   \n",
       "8877                7                  35                0        343850   \n",
       "\n",
       "      typedescription  article=3  article=6  article=P1  article=5  article=8  \\\n",
       "0                  15          1          0           0          1          0   \n",
       "1                  15          0          0           0          1          0   \n",
       "2                  15          0          1           0          0          0   \n",
       "3                  15          0          0           0          0          1   \n",
       "4                  15          1          0           0          1          0   \n",
       "...               ...        ...        ...         ...        ...        ...   \n",
       "8873               15          0          1           0          0          0   \n",
       "8874               15          0          0           0          1          0   \n",
       "8875               15          1          0           0          0          0   \n",
       "8876               15          0          1           0          0          0   \n",
       "8877               15          0          1           0          0          0   \n",
       "\n",
       "      ...  ccl_article=5  ccl_article=6  ccl_article=7  ccl_article=8  \\\n",
       "0     ...              1              0              0              0   \n",
       "1     ...              1              0              0              0   \n",
       "2     ...              0              1              0              0   \n",
       "3     ...              0              0              0             -1   \n",
       "4     ...              1              0              0              0   \n",
       "...   ...            ...            ...            ...            ...   \n",
       "8873  ...              0              1              0              0   \n",
       "8874  ...              1              0              0              0   \n",
       "8875  ...              0              0              0              0   \n",
       "8876  ...              0             -1              0              0   \n",
       "8877  ...              0              1              0              0   \n",
       "\n",
       "      ccl_article=9  ccl_article=p1  ccl_article=p4  ccl_article=p6  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "8873              0               0               0               0   \n",
       "8874              0               0               0               0   \n",
       "8875              0               0               0               0   \n",
       "8876              0               0               0               0   \n",
       "8877              0               0               0               0   \n",
       "\n",
       "      ccl_article=p7  importance  \n",
       "0                  0           4  \n",
       "1                  0           4  \n",
       "2                  0           4  \n",
       "3                  0           4  \n",
       "4                  0           4  \n",
       "...              ...         ...  \n",
       "8873               0           4  \n",
       "8874               0           4  \n",
       "8875               0           4  \n",
       "8876               0           3  \n",
       "8877               0           4  \n",
       "\n",
       "[8878 rows x 217 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.select_dtypes(include='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first examine non-binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'sharepointid'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique values in the training set : 8878\n",
      "Total number of unique values in the test set : 4760\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique values in the training set : {}\".format(train_df['sharepointid'].nunique()))\n",
    "print(\"Total number of unique values in the test set : {}\".format(test_df['sharepointid'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, this feature is like ids and can be dropped with no harm.\n",
    "train_df.drop('sharepointid',axis=1,inplace=True)\n",
    "test_df.drop('sharepointid',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'originatingbody'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique values in the training set : 13\n",
      "Total number of unique values in the test set : 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique values in the training set : {}\".format(train_df['originatingbody'].nunique()))\n",
    "print(\"Total number of unique values in the test set : {}\".format(test_df['originatingbody'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'respondentOrderEng'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique values in the training set : 46\n",
      "Total number of unique values in the test set : 46\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique values in the training set : {}\".format(train_df['respondentOrderEng'].nunique()))\n",
    "print(\"Total number of unique values in the test set : {}\".format(test_df['respondentOrderEng'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 'typedescription'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique values in the training set : 5\n",
      "Total number of unique values in the test set : 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique values in the training set : {}\".format(train_df['typedescription'].nunique()))\n",
    "print(\"Total number of unique values in the test set : {}\".format(test_df['typedescription'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 14, 18, 12, 19])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['typedescription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 14, 12])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['typedescription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature 'typedescription' looks like a categorical feature in disguise. We can use as it is or apply \n",
    "# onehotencoding.\n",
    "\n",
    "# let's now select only the binary features.\n",
    "binary_feat_train = list(train_df.select_dtypes(include='int64').nunique()[train_df.select_dtypes(include='int64').nunique()==2].index)\n",
    "binary_feat_test = list(test_df.select_dtypes(include='int64').nunique()[test_df.select_dtypes(include='int64').nunique()==2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of binary features in the training set : 192\n",
      "Number of binary features in the test set : 194\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of binary features in the training set : {}\".format(len(binary_feat_train)))\n",
    "print(\"Number of binary features in the test set : {}\".format(len(binary_feat_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "# there two more binary features in test set compared to the traing set. \n",
    "print(len(set(binary_feat_test).intersection(binary_feat_train)))\n",
    "print(len(set(binary_feat_train).intersection(binary_feat_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccl_article=12', 'ccl_article=25'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(binary_feat_test).difference(binary_feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99958\n",
       "1    0.00042\n",
       "Name: ccl_article=12, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['ccl_article=12'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99958\n",
       "1    0.00042\n",
       "Name: ccl_article=25, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['ccl_article=25'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.998085\n",
       "-1    0.001126\n",
       " 1    0.000788\n",
       "Name: ccl_article=12, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['ccl_article=12'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.999099\n",
       " 1    0.000563\n",
       "-1    0.000338\n",
       "Name: ccl_article=25, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['ccl_article=25'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since 99% instances in both these features belong to a single category, we can assume that they are basically\n",
    "# constant features and should be dropped.\n",
    "binary_feat_to_drop = list(set(binary_feat_test).difference(binary_feat_train))\n",
    "train_df.drop(binary_feat_to_drop,axis=1,inplace=True)\n",
    "test_df.drop(binary_feat_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_feat_test.remove(binary_feat_to_drop[0])\n",
    "binary_feat_test.remove(binary_feat_to_drop[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether any binary feature contains suspicious values, e.g., -1,999 etc.\n",
    "\n",
    "cols_train = [col for col in binary_feat_train for val in train_df[col].unique() if val!=0 and val!=1]\n",
    "cols_test = [col for col in binary_feat_test for val in test_df[col].unique() if val!=0 and val!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ccl_article=18']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ccl_article=18']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      " 0    0.998085\n",
      "-1    0.001915\n",
      "Name: ccl_article=18, dtype: float64\n",
      "----------------------------------------\n",
      "Test set\n",
      " 0    0.997269\n",
      "-1    0.002731\n",
      "Name: ccl_article=18, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set\")\n",
    "print(train_df['ccl_article=18'].value_counts(normalize=True))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Test set\")\n",
    "print(test_df['ccl_article=18'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, like before, we can drop this column. \n",
    "train_df.drop('ccl_article=18',axis=1,inplace=True)\n",
    "test_df.drop('ccl_article=18',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now look at the features which are binary in real but contains some garbage values.\n",
    "\n",
    "pseudo_bin_feat_train = list(train_df.select_dtypes(include='int64').nunique()[train_df.select_dtypes(include='int64').nunique()>2].index)\n",
    "pseudo_bin_feat_test = list(test_df.select_dtypes(include='int64').nunique()[test_df.select_dtypes(include='int64').nunique()>2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'importance'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pseudo_bin_feat_train).difference(pseudo_bin_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we have already investigated some of these non-binary features. Let's remove them.\n",
    "pseudo_bin_feat_train.remove('originatingbody')\n",
    "pseudo_bin_feat_train.remove('respondentOrderEng')\n",
    "pseudo_bin_feat_train.remove('typedescription')\n",
    "pseudo_bin_feat_train.remove('importance')\n",
    "pseudo_bin_feat_test.remove('originatingbody')\n",
    "pseudo_bin_feat_test.remove('respondentOrderEng')\n",
    "pseudo_bin_feat_test.remove('typedescription')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set \n",
      "\n",
      " 0    8117\n",
      " 1     700\n",
      "-1      61\n",
      "Name: ccl_article=1, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4315\n",
      " 1     404\n",
      "-1      41\n",
      "Name: ccl_article=1, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8449\n",
      " 1     332\n",
      "-1      97\n",
      "Name: ccl_article=10, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4514\n",
      " 1     185\n",
      "-1      61\n",
      "Name: ccl_article=10, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8718\n",
      " 1     136\n",
      "-1      24\n",
      "Name: ccl_article=11, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4657\n",
      " 1      86\n",
      "-1      17\n",
      "Name: ccl_article=11, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8121\n",
      " 1     694\n",
      "-1      63\n",
      "Name: ccl_article=13, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4341\n",
      " 1     364\n",
      "-1      55\n",
      "Name: ccl_article=13, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8829\n",
      "-1      46\n",
      " 1       3\n",
      "Name: ccl_article=14, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4731\n",
      "-1      28\n",
      " 1       1\n",
      "Name: ccl_article=14, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8322\n",
      " 1     471\n",
      "-1      85\n",
      "Name: ccl_article=2, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4457\n",
      " 1     258\n",
      "-1      45\n",
      "Name: ccl_article=2, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    7342\n",
      " 1    1250\n",
      "-1     286\n",
      "Name: ccl_article=3, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    3847\n",
      " 1     758\n",
      "-1     155\n",
      "Name: ccl_article=3, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8732\n",
      " 1      76\n",
      "-1      70\n",
      "Name: ccl_article=34, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4703\n",
      " 1      39\n",
      "-1      18\n",
      "Name: ccl_article=34, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8840\n",
      " 1      27\n",
      "-1      11\n",
      "Name: ccl_article=38, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4742\n",
      " 1      11\n",
      "-1       7\n",
      "Name: ccl_article=38, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8835\n",
      " 1      23\n",
      "-1      20\n",
      "Name: ccl_article=4, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4740\n",
      " 1      13\n",
      "-1       7\n",
      "Name: ccl_article=4, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    7434\n",
      " 1    1230\n",
      "-1     214\n",
      "Name: ccl_article=5, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    3966\n",
      " 1     693\n",
      "-1     101\n",
      "Name: ccl_article=5, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    4332\n",
      " 1    4005\n",
      "-1     541\n",
      "Name: ccl_article=6, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    2405\n",
      " 1    2133\n",
      "-1     222\n",
      "Name: ccl_article=6, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8824\n",
      "-1      35\n",
      " 1      19\n",
      "Name: ccl_article=7, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4723\n",
      "-1      20\n",
      " 1      17\n",
      "Name: ccl_article=7, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    7948\n",
      " 1     657\n",
      "-1     273\n",
      "Name: ccl_article=8, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4280\n",
      " 1     353\n",
      "-1     127\n",
      "Name: ccl_article=8, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8823\n",
      " 1      39\n",
      "-1      16\n",
      "Name: ccl_article=9, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4727\n",
      " 1      22\n",
      "-1      11\n",
      "Name: ccl_article=9, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8134\n",
      " 1     659\n",
      "-1      85\n",
      "Name: ccl_article=p1, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4336\n",
      " 1     368\n",
      "-1      56\n",
      "Name: ccl_article=p1, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8848\n",
      " 1      22\n",
      "-1       8\n",
      "Name: ccl_article=p4, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4750\n",
      " 1       6\n",
      "-1       4\n",
      "Name: ccl_article=p4, dtype: int64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    8857\n",
      " 1      14\n",
      "-1       7\n",
      "Name: ccl_article=p7, dtype: int64\n",
      "Test set \n",
      "\n",
      " 0    4751\n",
      " 1       7\n",
      "-1       2\n",
      "Name: ccl_article=p7, dtype: int64\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in pseudo_bin_feat_train:\n",
    "    print(\"Train set \\n\")\n",
    "    print(train_df[col].value_counts())\n",
    "    print(\"Test set \\n\")\n",
    "    print(test_df[col].value_counts())\n",
    "    print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature 'ccl_article=14' is quite peculliar. It has more entries for category -1 in both train and test sets \n",
    "# as compared tocategory 1. It could be a typo either in favour of -1 or +1. If we assume that 1 is a typo as it is \n",
    "# fewer in number, then we can replace 1 by -1 and treat it as null. But then it becomes a constant feature with one\n",
    "# unique value which is zero and some null entries (when we impute it by 0). In that situation, it is better to \n",
    "# drop this feature.\n",
    "# However, if we do reverse, i.e., replace -1 by 1, then it becomes a proper binary feature. Let's first go with the\n",
    "# first option. If our model performs poorly, we will try to tweak it.\n",
    "\n",
    "train_df.drop('ccl_article=14',axis=1,inplace=True)\n",
    "test_df.drop('ccl_article=14',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_bin_feat_train.remove('ccl_article=14')\n",
    "# for the rest of the features in pseudo_bin_feat_train, we will treat -1 as null entries and impute them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set \n",
      "\n",
      " 0    0.914282\n",
      " 1    0.078847\n",
      "-1    0.006871\n",
      "Name: ccl_article=1, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.906513\n",
      " 1    0.084874\n",
      "-1    0.008613\n",
      "Name: ccl_article=1, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.951678\n",
      " 1    0.037396\n",
      "-1    0.010926\n",
      "Name: ccl_article=10, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.948319\n",
      " 1    0.038866\n",
      "-1    0.012815\n",
      "Name: ccl_article=10, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.981978\n",
      " 1    0.015319\n",
      "-1    0.002703\n",
      "Name: ccl_article=11, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.978361\n",
      " 1    0.018067\n",
      "-1    0.003571\n",
      "Name: ccl_article=11, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.914733\n",
      " 1    0.078171\n",
      "-1    0.007096\n",
      "Name: ccl_article=13, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.911975\n",
      " 1    0.076471\n",
      "-1    0.011555\n",
      "Name: ccl_article=13, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.937373\n",
      " 1    0.053052\n",
      "-1    0.009574\n",
      "Name: ccl_article=2, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.936345\n",
      " 1    0.054202\n",
      "-1    0.009454\n",
      "Name: ccl_article=2, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.826988\n",
      " 1    0.140797\n",
      "-1    0.032214\n",
      "Name: ccl_article=3, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.808193\n",
      " 1    0.159244\n",
      "-1    0.032563\n",
      "Name: ccl_article=3, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.983555\n",
      " 1    0.008560\n",
      "-1    0.007885\n",
      "Name: ccl_article=34, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.988025\n",
      " 1    0.008193\n",
      "-1    0.003782\n",
      "Name: ccl_article=34, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.995720\n",
      " 1    0.003041\n",
      "-1    0.001239\n",
      "Name: ccl_article=38, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.996218\n",
      " 1    0.002311\n",
      "-1    0.001471\n",
      "Name: ccl_article=38, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.995157\n",
      " 1    0.002591\n",
      "-1    0.002253\n",
      "Name: ccl_article=4, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.995798\n",
      " 1    0.002731\n",
      "-1    0.001471\n",
      "Name: ccl_article=4, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.837351\n",
      " 1    0.138545\n",
      "-1    0.024105\n",
      "Name: ccl_article=5, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.833193\n",
      " 1    0.145588\n",
      "-1    0.021218\n",
      "Name: ccl_article=5, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.487948\n",
      " 1    0.451115\n",
      "-1    0.060937\n",
      "Name: ccl_article=6, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.505252\n",
      " 1    0.448109\n",
      "-1    0.046639\n",
      "Name: ccl_article=6, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.993918\n",
      "-1    0.003942\n",
      " 1    0.002140\n",
      "Name: ccl_article=7, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.992227\n",
      "-1    0.004202\n",
      " 1    0.003571\n",
      "Name: ccl_article=7, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.895247\n",
      " 1    0.074003\n",
      "-1    0.030750\n",
      "Name: ccl_article=8, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.899160\n",
      " 1    0.074160\n",
      "-1    0.026681\n",
      "Name: ccl_article=8, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.993805\n",
      " 1    0.004393\n",
      "-1    0.001802\n",
      "Name: ccl_article=9, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.993067\n",
      " 1    0.004622\n",
      "-1    0.002311\n",
      "Name: ccl_article=9, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.916197\n",
      " 1    0.074228\n",
      "-1    0.009574\n",
      "Name: ccl_article=p1, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.910924\n",
      " 1    0.077311\n",
      "-1    0.011765\n",
      "Name: ccl_article=p1, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.996621\n",
      " 1    0.002478\n",
      "-1    0.000901\n",
      "Name: ccl_article=p4, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.997899\n",
      " 1    0.001261\n",
      "-1    0.000840\n",
      "Name: ccl_article=p4, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "Train set \n",
      "\n",
      " 0    0.997635\n",
      " 1    0.001577\n",
      "-1    0.000788\n",
      "Name: ccl_article=p7, dtype: float64\n",
      "Test set \n",
      "\n",
      " 0    0.998109\n",
      " 1    0.001471\n",
      "-1    0.000420\n",
      "Name: ccl_article=p7, dtype: float64\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# missing value imputation\n",
    "# but before that, let's check the category distribution in each binary feature with null values\n",
    "for col in pseudo_bin_feat_train:\n",
    "    print(\"Train set \\n\")\n",
    "    print(train_df[col].value_counts(normalize=True))\n",
    "    print(\"Test set \\n\")\n",
    "    print(test_df[col].value_counts(normalize=True))\n",
    "    print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop!! looks like we can drop even more features, e.g. features with 99% dominance by one category.\n",
    "cols_to_drop = ['ccl_article=38','ccl_article=4', 'ccl_article=7', 'ccl_article=9','ccl_article=p4','ccl_article=p7']\n",
    "train_df.drop(cols_to_drop,axis=1,inplace=True)\n",
    "test_df.drop(cols_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_drop:\n",
    "    pseudo_bin_feat_train.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['judgementdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the datetime fetaure 'judgementdate' and break it down into several parts.\n",
    "\n",
    "train_df['judge_year'] = train_df['judgementdate'].apply(lambda x:int(x.split(\"/\")[-1].strip()))\n",
    "test_df['judge_year'] = test_df['judgementdate'].apply(lambda x:int(x.split(\"/\")[-1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in the col judgementyear in the training set : [1968, 1969, 1971, 1974, 1975, 1976, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
      "\n",
      "\n",
      "unique values in the col judgementyear in the test set : [1961, 1968, 1970, 1972, 1975, 1976, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n"
     ]
    }
   ],
   "source": [
    "# how many different judgement years are there?\n",
    "print(\"unique values in the col judgementyear in the training set :\", sorted(train_df['judge_year'].unique()))\n",
    "print(\"\\n\")\n",
    "print(\"unique values in the col judgementyear in the test set :\", sorted(test_df['judge_year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's club the years in decades and look at the distribution of importance vs judge_year\n",
    "\n",
    "def year_to_decade(year):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if year>=1960 and year<=1969:\n",
    "        return \"19_60s\"\n",
    "    elif year>=1970 and year<=1979:\n",
    "        return \"19_70s\"\n",
    "    elif year>=1980 and year<=1989:\n",
    "        return \"19_80s\"\n",
    "    elif year>=1990 and year<=1999:\n",
    "        return \"19_90s\"\n",
    "    elif year>=2000 and year<=2009:\n",
    "        return \"20_10s\"\n",
    "    else:\n",
    "        return \"20_20s\"\n",
    "    \n",
    "    \n",
    "train_df['judge_decade'] = train_df['judge_year'].apply(year_to_decade)\n",
    "test_df['judge_decade'] = test_df['judge_year'].apply(year_to_decade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judge_year</th>\n",
       "      <th>judge_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>20_20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>20_20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>20_20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   judge_year judge_decade\n",
       "0        2009       20_10s\n",
       "1        2018       20_20s\n",
       "2        2012       20_20s\n",
       "3        2014       20_20s\n",
       "4        2009       20_10s\n",
       "5        2002       20_10s\n",
       "6        2006       20_10s\n",
       "7        2007       20_10s\n",
       "8        2001       20_10s\n",
       "9        2008       20_10s"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['judge_year','judge_decade']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='judge_decade', ylabel='count'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.countplot('judge_decade',hue='importance',data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the distribution, it is clear that importance of cases filed has increased with decades. We will use it as a\n",
    "# feature and drop the judge_year column.\n",
    "train_df.drop('judge_year',axis=1,inplace=True)\n",
    "test_df.drop('judge_year',axis=1,inplace=True)\n",
    "\n",
    "# as of now, we will not be engineering the feature judgementdate anymore and won't use it during training. If, in\n",
    "# future, we need to improve our model by adding some features, we will come back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "cardinality of country.alpha2 is 46\n",
      "cardinality of doctypebranch is 3\n",
      "cardinality of judgementdate is 1906\n",
      "cardinality of originatingbody_name is 13\n",
      "cardinality of judge_decade is 6\n",
      "-------------------------------------------------\n",
      "Test set\n",
      "cardinality of country.alpha2 is 46\n",
      "cardinality of doctypebranch is 3\n",
      "cardinality of judgementdate is 1584\n",
      "cardinality of originatingbody_name is 13\n",
      "cardinality of judge_decade is 6\n"
     ]
    }
   ],
   "source": [
    "# Let's now drop cols with high cardinality\n",
    "print(\"Training set\")\n",
    "for col in train_df.select_dtypes(include='object').columns:\n",
    "    print(\"cardinality of {} is {}\".format(col, train_df[col].nunique()))\n",
    "print(\"-------------------------------------------------\")    \n",
    "print(\"Test set\")\n",
    "for col in test_df.select_dtypes(include='object').columns:\n",
    "    print(\"cardinality of {} is {}\".format(col, test_df[col].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['country.alpha2','judgementdate'],axis=1,inplace=True)\n",
    "test_df.drop(['country.alpha2','judgementdate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set after feature removal: (8878, 210)\n",
      "The shape of the test set after feature removal: (4760, 209)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training set after feature removal: {}\".format(train_df.shape))\n",
    "print(\"The shape of the test set after feature removal: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now define our feature matrix and target variable\n",
    "X = train_df.drop('importance',axis=1)\n",
    "y = train_df[['importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctypebranch</th>\n",
       "      <th>originatingbody</th>\n",
       "      <th>originatingbody_name</th>\n",
       "      <th>rank</th>\n",
       "      <th>respondentOrderEng</th>\n",
       "      <th>separateopinion</th>\n",
       "      <th>typedescription</th>\n",
       "      <th>article=3</th>\n",
       "      <th>article=6</th>\n",
       "      <th>article=P1</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_article=13</th>\n",
       "      <th>ccl_article=2</th>\n",
       "      <th>ccl_article=3</th>\n",
       "      <th>ccl_article=34</th>\n",
       "      <th>ccl_article=5</th>\n",
       "      <th>ccl_article=6</th>\n",
       "      <th>ccl_article=8</th>\n",
       "      <th>ccl_article=p1</th>\n",
       "      <th>ccl_article=p6</th>\n",
       "      <th>judge_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>4</td>\n",
       "      <td>First Section</td>\n",
       "      <td>685.417419</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMMITTEE</td>\n",
       "      <td>26</td>\n",
       "      <td>Second Section Committee</td>\n",
       "      <td>2641.901855</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20_20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>23</td>\n",
       "      <td>Fith Section</td>\n",
       "      <td>942.213440</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20_20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>5</td>\n",
       "      <td>Second Section</td>\n",
       "      <td>1121.770142</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20_20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>4</td>\n",
       "      <td>First Section</td>\n",
       "      <td>704.821594</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20_10s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  doctypebranch  originatingbody      originatingbody_name         rank  \\\n",
       "0       CHAMBER                4             First Section   685.417419   \n",
       "1     COMMITTEE               26  Second Section Committee  2641.901855   \n",
       "2       CHAMBER               23              Fith Section   942.213440   \n",
       "3       CHAMBER                5            Second Section  1121.770142   \n",
       "4       CHAMBER                4             First Section   704.821594   \n",
       "\n",
       "   respondentOrderEng  separateopinion  typedescription  article=3  article=6  \\\n",
       "0                  38                0               15          1          0   \n",
       "1                  47                0               15          0          0   \n",
       "2                  43                1               15          0          1   \n",
       "3                  46                1               15          0          0   \n",
       "4                  38                0               15          1          0   \n",
       "\n",
       "   article=P1  ...  ccl_article=13  ccl_article=2  ccl_article=3  \\\n",
       "0           0  ...               0              0              1   \n",
       "1           0  ...               0              0              0   \n",
       "2           0  ...               1              0              0   \n",
       "3           0  ...               0              0              0   \n",
       "4           0  ...               0              1              1   \n",
       "\n",
       "   ccl_article=34  ccl_article=5  ccl_article=6  ccl_article=8  \\\n",
       "0               0              1              0              0   \n",
       "1               0              1              0              0   \n",
       "2               0              0              1              0   \n",
       "3               0              0              0             -1   \n",
       "4               0              1              0              0   \n",
       "\n",
       "   ccl_article=p1  ccl_article=p6  judge_decade  \n",
       "0               0               0        20_10s  \n",
       "1               0               0        20_20s  \n",
       "2               0               0        20_20s  \n",
       "3               0               0        20_20s  \n",
       "4               0               0        20_10s  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   importance\n",
       "0           4\n",
       "1           4\n",
       "2           4\n",
       "3           4\n",
       "4           4"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.650372\n",
       "3    0.226515\n",
       "1    0.065555\n",
       "2    0.057558\n",
       "Name: importance, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at our target variable\n",
    "y['importance'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the cardinality of the target variable is greater than 2, it is a multiclass classification problem. Our \n",
    "# target metric is accuracy_score and we will optimize the metric logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    0.914282\n",
      " 1    0.078847\n",
      "-1    0.006871\n",
      "Name: ccl_article=1, dtype: float64\n",
      " 0    0.951678\n",
      " 1    0.037396\n",
      "-1    0.010926\n",
      "Name: ccl_article=10, dtype: float64\n",
      " 0    0.981978\n",
      " 1    0.015319\n",
      "-1    0.002703\n",
      "Name: ccl_article=11, dtype: float64\n",
      " 0    0.914733\n",
      " 1    0.078171\n",
      "-1    0.007096\n",
      "Name: ccl_article=13, dtype: float64\n",
      " 0    0.937373\n",
      " 1    0.053052\n",
      "-1    0.009574\n",
      "Name: ccl_article=2, dtype: float64\n",
      " 0    0.826988\n",
      " 1    0.140797\n",
      "-1    0.032214\n",
      "Name: ccl_article=3, dtype: float64\n",
      " 0    0.983555\n",
      " 1    0.008560\n",
      "-1    0.007885\n",
      "Name: ccl_article=34, dtype: float64\n",
      " 0    0.837351\n",
      " 1    0.138545\n",
      "-1    0.024105\n",
      "Name: ccl_article=5, dtype: float64\n",
      " 0    0.487948\n",
      " 1    0.451115\n",
      "-1    0.060937\n",
      "Name: ccl_article=6, dtype: float64\n",
      " 0    0.895247\n",
      " 1    0.074003\n",
      "-1    0.030750\n",
      "Name: ccl_article=8, dtype: float64\n",
      " 0    0.916197\n",
      " 1    0.074228\n",
      "-1    0.009574\n",
      "Name: ccl_article=p1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# missing value imputation\n",
    "for col in pseudo_bin_feat_train:\n",
    "    print(train_df[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume -1 to represent null values and try to impute it. To impute missing values, we can use the following \n",
    "# strategies - 'mean', 'median', 'most_frequent', 'constant'. If a feature is almost entirely dominated by a \n",
    "# specific category, it is logical to use 'most_frequent' strategy. 'mean' could be used for a more balanced\n",
    "# category distribution. 'mean'/median'/'constant' strategy won't work well in this case since we are dealing \n",
    "# with binary features.\n",
    "# However, looking at the above result, one can also think of -1 as a typo since it's percentage is very low.\n",
    "# Let's first try imputing all -1 using the 'most_frequent' strategy. Later, if needed (to enhance the model's\n",
    "# performance), we will try replacing all -1 by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the feature matrix is : (8878, 225)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the feature matrix is : {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model pipeline\n",
    "\n",
    "def build_pipeline(model):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(missing_values=-1,strategy='most_frequent')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('classifier', model)\n",
    "                   ])\n",
    "        \n",
    "    return pipeline    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search \n",
    "\n",
    "def grid_search(model,param_dict):\n",
    "    \n",
    "    grid_cv = GridSearchCV(model,param_grid=param_dict, scoring='neg_log_loss', verbose=2)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will perform coarse scanning. Then, if needed, finer scanning would be tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train : (7102, 225)\n",
      "The shape of X_val : (1776, 225)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and validation subsets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=21)\n",
    "\n",
    "print(\"The shape of X_train : {}\".format(X_train.shape))\n",
    "print(\"The shape of X_val : {}\".format(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "4    0.649113\n",
      "3    0.226978\n",
      "1    0.066179\n",
      "2    0.057730\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "\n",
      "Validation Set\n",
      "4    0.655405\n",
      "3    0.224662\n",
      "1    0.063063\n",
      "2    0.056869\n",
      "Name: importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# distribution of different classes in training and validation sets\n",
    "print(\"Train Set\")\n",
    "print(y_train['importance'].value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set\")\n",
    "print(y_val['importance'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_eval_model(model, param_dict):\n",
    "    \n",
    "    model_name = str(model).split(\"(\")[0]\n",
    "    \n",
    "    pipeline = build_pipeline(model)\n",
    "    grid_cv = grid_search(pipeline,param_dict)\n",
    "\n",
    "    # fit the model to the train set\n",
    "    grid_cv.fit(X_train,y_train)\n",
    "\n",
    "    # predict on the train set\n",
    "    train_pred = grid_cv.predict(X_train)\n",
    "\n",
    "    # predict on the validation set\n",
    "    val_pred = grid_cv.predict(X_val)\n",
    "\n",
    "    # evaluate the model on the train set\n",
    "    train_score = accuracy_score(y_true=y_train, y_pred=train_pred)\n",
    "\n",
    "    # evaluate the model on the validation set\n",
    "    val_score = accuracy_score(y_true=y_val, y_pred=val_pred)\n",
    "\n",
    "\n",
    "    print(\"The best parameter for the model {} is {}.\\n\".format(model_name, grid_cv.best_params_))\n",
    "    print(\"The best score obtained for the model {} during grid search is {}.\\n\".format(model_name,grid_cv.best_score_))\n",
    "    print(\"The train score of the model {} is {}.\\n\".format(model_name,train_score))\n",
    "    print(\"The validation score of the model {} is {}.\".format(model_name,val_score))    \n",
    "    \n",
    "    return grid_cv, train_score, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K nearest neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=uniform ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=uniform, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=uniform ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=uniform, total=   2.8s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=uniform ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=uniform, total=   3.0s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=uniform ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=uniform, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=uniform ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=uniform, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=distance .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=distance, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=distance .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=distance, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=distance .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=distance, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=distance .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=distance, total=   2.9s\n",
      "[CV] classifier__n_neighbors=5, classifier__weights=distance .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=5, classifier__weights=distance, total=   2.9s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=uniform, total=   3.0s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=uniform, total=   3.0s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=uniform, total=   3.1s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=uniform, total=   3.0s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=uniform, total=   3.3s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=distance, total=   3.0s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=distance, total=   3.1s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=distance, total=   3.0s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=distance, total=   3.0s\n",
      "[CV] classifier__n_neighbors=10, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=10, classifier__weights=distance, total=   3.2s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=uniform, total=   3.1s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=uniform, total=   3.4s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=uniform, total=   3.2s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=uniform, total=   3.3s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=uniform, total=   3.2s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=distance, total=   3.1s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=distance, total=   3.1s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=distance, total=   3.0s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=distance, total=   3.0s\n",
      "[CV] classifier__n_neighbors=15, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=15, classifier__weights=distance, total=   3.0s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=uniform, total=   3.0s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=uniform, total=   3.0s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=uniform, total=   3.1s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=uniform, total=   3.7s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=uniform, total=   4.2s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=distance, total=   4.8s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=distance, total=   4.1s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=distance, total=   4.1s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=distance, total=   3.6s\n",
      "[CV] classifier__n_neighbors=20, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=20, classifier__weights=distance, total=   3.7s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=uniform, total=   4.1s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=uniform, total=   4.2s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=uniform, total=   3.7s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=uniform, total=   3.9s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=uniform, total=   4.3s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=distance, total=   3.9s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=distance, total=   3.6s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=distance, total=   3.4s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=distance, total=   3.3s\n",
      "[CV] classifier__n_neighbors=25, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=25, classifier__weights=distance, total=   3.3s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=uniform, total=   3.4s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=uniform, total=   3.5s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=uniform, total=   3.4s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=uniform, total=   3.3s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=uniform .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=uniform, total=   3.6s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=distance, total=   3.6s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=distance, total=   3.8s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=distance, total=   3.9s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=distance, total=   4.0s\n",
      "[CV] classifier__n_neighbors=30, classifier__weights=distance ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__n_neighbors=30, classifier__weights=distance, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.4min finished\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter for the model KNeighborsClassifier is {'classifier__n_neighbors': 30, 'classifier__weights': 'distance'}.\n",
      "\n",
      "The best score obtained for the model KNeighborsClassifier during grid search is -0.8810155578498808.\n",
      "\n",
      "The train score of the model KNeighborsClassifier is 1.0.\n",
      "\n",
      "The validation score of the model KNeighborsClassifier is 0.8006756756756757.\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "#param_dict = [\n",
    "#              {'classifier__n_neighbors': list(np.arange(5,35,5))},\n",
    "#              {'classifier__weights': ['uniform','distance']}\n",
    "#             ]\n",
    "\n",
    "param_dict = {'classifier__n_neighbors': list(np.arange(5,35,5)),\n",
    "              'classifier__weights': ['uniform','distance']}\n",
    "\n",
    "grid_cv_knn, knn_train_score, knn_val_score = fit_and_eval_model(model,param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] classifier__C=0.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=0.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=0.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=0.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=0.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=0.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=0.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=0.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=0.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=0.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=0.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=0.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=1.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=1.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=1.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=1.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=1.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=1.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=1.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=1.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=1.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=1.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=1.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=1.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=2.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=2.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=2.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=2.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=2.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=2.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.0, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=2.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=2.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=2.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=2.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=2.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=2.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=2.5, classifier__class_weight=balanced, total=   0.7s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=3.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=3.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=3.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=3.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=3.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.0, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.0, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=3.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=3.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=3.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=3.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=3.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=3.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=3.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=4.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=4.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=4.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=4.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=4.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=4.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=4.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=4.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=4.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=4.5, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.5, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=4.5, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=4.5, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=5.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=5.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=5.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=None ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 666, in _logistic_regression_path\n",
      "    classes=classes, y=y)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 64, in compute_class_weight\n",
      "    \" got: %r\" % class_weight)\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'None'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . classifier__C=5.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=None ................\n",
      "[CV] . classifier__C=5.0, classifier__class_weight=None, total=   0.1s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=5.0, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=5.0, classifier__class_weight=balanced, total=   0.6s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=5.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=5.0, classifier__class_weight=balanced, total=   0.5s\n",
      "[CV] classifier__C=5.0, classifier__class_weight=balanced ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   33.0s finished\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__C=5.0, classifier__class_weight=balanced, total=   0.5s\n",
      "The best parameter for the model LogisticRegression is {'classifier__C': 0.5, 'classifier__class_weight': 'balanced'}.\n",
      "\n",
      "The best score obtained for the model LogisticRegression during grid search is -0.6281117917000996.\n",
      "\n",
      "The train score of the model LogisticRegression is 0.812869614193185.\n",
      "\n",
      "The validation score of the model LogisticRegression is 0.7888513513513513.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "param_dict = {'classifier__C': list(np.arange(0.5,5.5,0.5)),\n",
    "              'classifier__class_weight': ['None','balanced']}\n",
    "\n",
    "grid_cv_lr, lr_train_score, lr_val_score = fit_and_eval_model(model,param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer',\n",
       "                 SimpleImputer(missing_values=-1, strategy='most_frequent')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.5, multi_class='multinomial'))])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.1s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.1s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.1s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.1s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.1s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   1.2s\n",
      "[CV] classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=balanced, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   1.3s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=gini, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=90, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=110, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=sqrt, classifier__n_estimators=130, total=   1.0s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.5s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=50, total=   0.4s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=70, total=   0.6s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=90, total=   0.7s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=110, total=   0.8s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n",
      "[CV] classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__class_weight=None, classifier__criterion=entropy, classifier__max_features=log2, classifier__n_estimators=130, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.5min finished\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter for the model RandomForestClassifier is {'classifier__class_weight': 'balanced', 'classifier__criterion': 'entropy', 'classifier__max_features': 'sqrt', 'classifier__n_estimators': 130}.\n",
      "\n",
      "The best score obtained for the model RandomForestClassifier during grid search is -0.44147217352160356.\n",
      "\n",
      "The train score of the model RandomForestClassifier is 1.0.\n",
      "\n",
      "The validation score of the model RandomForestClassifier is 0.8693693693693694.\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "param_dict = {'classifier__n_estimators': list(np.arange(50,140,20)),\n",
    "              'classifier__criterion': ['gini','entropy'],\n",
    "              'classifier__max_features':['sqrt','log2'],\n",
    "              'classifier__class_weight':['balanced',None]\n",
    "             }\n",
    "\n",
    "grid_cv_rf, rf_train_score, rf_val_score = fit_and_eval_model(model,param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.1,1,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=50 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:00:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=50, total=   2.2s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=50 ......\n",
      "[22:00:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=50, total=   2.2s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=50 ......\n",
      "[22:00:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=50, total=   2.1s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=50 ......\n",
      "[22:00:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=50, total=   2.0s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=50 ......\n",
      "[22:00:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=50, total=   2.0s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=70 ......\n",
      "[22:00:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=70, total=   2.9s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=70 ......\n",
      "[22:00:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=70, total=   2.8s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=70 ......\n",
      "[22:00:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=70, total=   2.8s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=70 ......\n",
      "[22:00:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=70, total=   2.8s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=70 ......\n",
      "[22:00:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=70, total=   2.8s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=90 ......\n",
      "[22:00:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=90, total=   3.5s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=90 ......\n",
      "[22:00:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=90, total=   3.7s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=90 ......\n",
      "[22:00:38] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=90 ......\n",
      "[22:00:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=90 ......\n",
      "[22:00:47] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=110 .....\n",
      "[22:00:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=110, total=   5.4s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=110 .....\n",
      "[22:00:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=110, total=   5.3s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=110 .....\n",
      "[22:01:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=110, total=   5.3s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=110 .....\n",
      "[22:01:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=110 .....\n",
      "[22:01:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=110, total=   5.7s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=130 .....\n",
      "[22:01:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=130 .....\n",
      "[22:01:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=130, total=   6.2s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=130 .....\n",
      "[22:01:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=130 .....\n",
      "[22:01:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.1, classifier__n_estimators=130 .....\n",
      "[22:01:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=50 ......\n",
      "[22:01:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=50 ......\n",
      "[22:01:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=50 ......\n",
      "[22:01:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=50 ......\n",
      "[22:01:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=50 ......\n",
      "[22:01:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=70 ......\n",
      "[22:02:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=70 ......\n",
      "[22:02:04] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=70 ......\n",
      "[22:02:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=70 ......\n",
      "[22:02:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=70 ......\n",
      "[22:02:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=90 ......\n",
      "[22:02:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=90 ......\n",
      "[22:02:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=90 ......\n",
      "[22:02:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=90 ......\n",
      "[22:02:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=90 ......\n",
      "[22:02:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=110 .....\n",
      "[22:02:39] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=110 .....\n",
      "[22:02:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=110 .....\n",
      "[22:02:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=110 .....\n",
      "[22:02:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=110 .....\n",
      "[22:03:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=130 .....\n",
      "[22:03:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=130 .....\n",
      "[22:03:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=130, total=   6.6s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=130 .....\n",
      "[22:03:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=130 .....\n",
      "[22:03:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.2, classifier__n_estimators=130 .....\n",
      "[22:03:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50 \n",
      "[22:03:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50 \n",
      "[22:03:39] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50 \n",
      "[22:03:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50 \n",
      "[22:03:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50 \n",
      "[22:03:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70 \n",
      "[22:03:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70 \n",
      "[22:03:52] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70 \n",
      "[22:03:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70 \n",
      "[22:03:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70 \n",
      "[22:04:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90 \n",
      "[22:04:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90 \n",
      "[22:04:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90 \n",
      "[22:04:14] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90 \n",
      "[22:04:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90 \n",
      "[22:04:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110 \n",
      "[22:04:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110, total=   5.3s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110 \n",
      "[22:04:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110 \n",
      "[22:04:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110 \n",
      "[22:04:43] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110 \n",
      "[22:04:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130 \n",
      "[22:04:53] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130 \n",
      "[22:04:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130 \n",
      "[22:05:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130 \n",
      "[22:05:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130, total=   7.2s\n",
      "[CV] classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130 \n",
      "[22:05:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.30000000000000004, classifier__n_estimators=130, total=   6.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=50 ......\n",
      "[22:05:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=50 ......\n",
      "[22:05:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=50 ......\n",
      "[22:05:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=50 ......\n",
      "[22:05:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=50 ......\n",
      "[22:05:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=70 ......\n",
      "[22:05:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=70 ......\n",
      "[22:05:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=70 ......\n",
      "[22:05:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=70 ......\n",
      "[22:05:47] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=70 ......\n",
      "[22:05:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=70, total=   3.6s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=90 ......\n",
      "[22:05:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=90, total=   4.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=90 ......\n",
      "[22:05:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=90, total=   4.4s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=90 ......\n",
      "[22:06:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=90 ......\n",
      "[22:06:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=90 ......\n",
      "[22:06:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=110 .....\n",
      "[22:06:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=110 .....\n",
      "[22:06:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=110 .....\n",
      "[22:06:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=110 .....\n",
      "[22:06:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=110 .....\n",
      "[22:06:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=130 .....\n",
      "[22:06:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=130 .....\n",
      "[22:06:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=130, total=   6.0s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=130 .....\n",
      "[22:06:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=130 .....\n",
      "[22:07:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=130, total=   6.0s\n",
      "[CV] classifier__learning_rate=0.4, classifier__n_estimators=130 .....\n",
      "[22:07:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.4, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=50 ......\n",
      "[22:07:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=50, total=   2.9s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=50 ......\n",
      "[22:07:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=50 ......\n",
      "[22:07:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=50 ......\n",
      "[22:07:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=50 ......\n",
      "[22:07:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=70 ......\n",
      "[22:07:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=70 ......\n",
      "[22:07:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=70 ......\n",
      "[22:07:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=70 ......\n",
      "[22:07:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=70 ......\n",
      "[22:07:38] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=90 ......\n",
      "[22:07:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=90 ......\n",
      "[22:07:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=90 ......\n",
      "[22:07:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=90 ......\n",
      "[22:07:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=90 ......\n",
      "[22:07:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=110 .....\n",
      "[22:08:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=110 .....\n",
      "[22:08:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=110 .....\n",
      "[22:08:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=110 .....\n",
      "[22:08:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=110 .....\n",
      "[22:08:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=130 .....\n",
      "[22:08:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=130 .....\n",
      "[22:08:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=130, total=   6.0s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=130 .....\n",
      "[22:08:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=130 .....\n",
      "[22:08:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.5, classifier__n_estimators=130 .....\n",
      "[22:08:52] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.5, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=50 ......\n",
      "[22:08:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=50 ......\n",
      "[22:09:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=50 ......\n",
      "[22:09:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=50 ......\n",
      "[22:09:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=50 ......\n",
      "[22:09:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=70 ......\n",
      "[22:09:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=70, total=   3.8s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=70 ......\n",
      "[22:09:14] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=70 ......\n",
      "[22:09:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=70 ......\n",
      "[22:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=70 ......\n",
      "[22:09:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=90 ......\n",
      "[22:09:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=90 ......\n",
      "[22:09:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=90 ......\n",
      "[22:09:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=90 ......\n",
      "[22:09:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=90 ......\n",
      "[22:09:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=110 .....\n",
      "[22:09:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=110 .....\n",
      "[22:09:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=110 .....\n",
      "[22:09:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=110 .....\n",
      "[22:10:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=110 .....\n",
      "[22:10:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=130 .....\n",
      "[22:10:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=130 .....\n",
      "[22:10:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=130 .....\n",
      "[22:10:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=130 .....\n",
      "[22:10:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.6, classifier__n_estimators=130 .....\n",
      "[22:10:39] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.6, classifier__n_estimators=130, total=   6.0s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50 \n",
      "[22:10:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50 \n",
      "[22:10:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50 \n",
      "[22:10:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:10:53] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50, total=   2.6s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50 \n",
      "[22:10:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70 \n",
      "[22:10:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70 \n",
      "[22:11:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70 \n",
      "[22:11:04] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70 \n",
      "[22:11:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70 \n",
      "[22:11:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=70, total=   3.8s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90 \n",
      "[22:11:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90 \n",
      "[22:11:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90 \n",
      "[22:11:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90 \n",
      "[22:11:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90 \n",
      "[22:11:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110 \n",
      "[22:11:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110 \n",
      "[22:11:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110 \n",
      "[22:11:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110 \n",
      "[22:11:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110, total=   5.1s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110 \n",
      "[22:11:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130 \n",
      "[22:12:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130 \n",
      "[22:12:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130 \n",
      "[22:12:14] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130 \n",
      "[22:12:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130, total=   6.0s\n",
      "[CV] classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130 \n",
      "[22:12:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.7000000000000001, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=50 ......\n",
      "[22:12:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=50 ......\n",
      "[22:12:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=50 ......\n",
      "[22:12:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=50 ......\n",
      "[22:12:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=50 ......\n",
      "[22:12:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=70 ......\n",
      "[22:12:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=70 ......\n",
      "[22:12:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=70 ......\n",
      "[22:12:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=70 ......\n",
      "[22:12:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=70 ......\n",
      "[22:12:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=90 ......\n",
      "[22:13:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=90 ......\n",
      "[22:13:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=90 ......\n",
      "[22:13:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=90, total=   4.8s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=90 ......\n",
      "[22:13:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=90 ......\n",
      "[22:13:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=110 .....\n",
      "[22:13:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=110 .....\n",
      "[22:13:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=110 .....\n",
      "[22:13:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=110 .....\n",
      "[22:13:39] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=110 .....\n",
      "[22:13:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=130 .....\n",
      "[22:13:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=130 .....\n",
      "[22:13:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=130 .....\n",
      "[22:14:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=130 .....\n",
      "[22:14:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.8, classifier__n_estimators=130 .....\n",
      "[22:14:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.8, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=50 ......\n",
      "[22:14:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=50 ......\n",
      "[22:14:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=50 ......\n",
      "[22:14:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=50, total=   2.5s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=50 ......\n",
      "[22:14:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=50 ......\n",
      "[22:14:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=50, total=   2.4s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=70 ......\n",
      "[22:14:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=70, total=   3.4s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=70 ......\n",
      "[22:14:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=70 ......\n",
      "[22:14:38] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=70 ......\n",
      "[22:14:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=70 ......\n",
      "[22:14:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=70, total=   3.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=90 ......\n",
      "[22:14:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=90 ......\n",
      "[22:14:53] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=90 ......\n",
      "[22:14:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=90 ......\n",
      "[22:15:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=90, total=   4.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=90 ......\n",
      "[22:15:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=90, total=   4.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=110 .....\n",
      "[22:15:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=110, total=   5.7s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=110 .....\n",
      "[22:15:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=110 .....\n",
      "[22:15:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=110 .....\n",
      "[22:15:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=110 .....\n",
      "[22:15:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=110, total=   5.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=130 .....\n",
      "[22:15:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=130 .....\n",
      "[22:15:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=130, total=   6.1s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=130 .....\n",
      "[22:15:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=130, total=   6.3s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=130 .....\n",
      "[22:15:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=130, total=   6.2s\n",
      "[CV] classifier__learning_rate=0.9, classifier__n_estimators=130 .....\n",
      "[22:16:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.9, classifier__n_estimators=130, total=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 16.0min finished\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/admin1/anaconda3/envs/my_env_py3.7.4/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:16:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The best parameter for the model XGBClassifier is {'classifier__learning_rate': 0.2, 'classifier__n_estimators': 90}.\n",
      "\n",
      "The best score obtained for the model XGBClassifier during grid search is -0.345432725675038.\n",
      "\n",
      "The train score of the model XGBClassifier is 0.953675021120811.\n",
      "\n",
      "The validation score of the model XGBClassifier is 0.8778153153153153.\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "param_dict = {'classifier__n_estimators': list(np.arange(50,140,20)),\n",
    "              'classifier__learning_rate': np.arange(0.1,1,0.1)\n",
    "              #'classifier__booster': ['gbtree','gblinear','dart']\n",
    "             }\n",
    "\n",
    "grid_cv_xgb, xgb_train_score, xgb_val_score = fit_and_eval_model(model,param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
